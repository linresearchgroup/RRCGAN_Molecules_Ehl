{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "564dafda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 19:09:40.328286: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import rc, rcParams\n",
    "\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "import multiprocessing\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import (Input, Dropout, LSTM, Reshape, LeakyReLU,\n",
    "                          Concatenate, ReLU, Flatten, Dense, Embedding,\n",
    "                          BatchNormalization, Activation, SpatialDropout1D,\n",
    "                          Conv2D, MaxPooling2D, UpSampling2D, Lambda)\n",
    "from tensorflow.keras.models     import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses     import mse, binary_crossentropy\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.metrics import  mean_squared_error as mse_keras\n",
    "from tensorflow.keras.backend import argmax as argmax\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow import one_hot\n",
    "from tensorflow.keras.models import Sequential \n",
    "\n",
    "from tensorflow.keras.utils import  to_categorical\n",
    "from tensorflow import random as randomtf\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.lines as mlines\n",
    "from   matplotlib.lines import Line2D\n",
    "from   matplotlib.colors import ListedColormap\n",
    "import matplotlib.ticker as tk\n",
    "\n",
    "from progressbar import ProgressBar\n",
    "import seaborn as sns\n",
    "\n",
    "from chainer_chemistry.dataset.preprocessors import GGNNPreprocessor, construct_atomic_number_array\n",
    "preprocessor = GGNNPreprocessor()\n",
    "from rdkit import rdBase\n",
    "rdBase.DisableLog('rdApp.error')\n",
    "from rdkit import Chem\n",
    "import ntpath\n",
    "from scipy.stats import truncnorm\n",
    "import sys\n",
    "sys.path.append(\"./../utils/\")\n",
    "from general import *\n",
    "\n",
    "\"\"\" fix all the seeds,results are still slighthly different \"\"\"\n",
    "randomtf.set_seed(10)\n",
    "os.environ['PYTHONHASHSEED'] = '10'\n",
    "np.random.seed(420)\n",
    "random.seed(123450)\n",
    "from progressbar import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa193c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the random seeds and GPU RAM allocation\n",
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.3)\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1, gpu_options=gpu_options)\n",
    "tf.compat.v1.set_random_seed(1234)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "tf.compat.v1.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0597c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the font !!!!!!!!!!!!!!!!!!!!!\n",
    "# switch to Arial\n",
    "# if not working: delet ~/.catch/matplotlib\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.rcParams['ps.useafm'] = True\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "mpl.font_manager.FontManager()\n",
    "\n",
    "rc('font', weight='bold')\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "plt.scatter([10, 55], [10, 55])\n",
    "ax.tick_params(axis='both', length=0, width=1.5, colors='black', grid_alpha=0, labelsize=20)\n",
    "plt.xlabel('!!!Ariaaaal', fontname='Arial', fontsize=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f38a886",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" reading and preprocessing data\"\"\"\n",
    "with open('./../data/trainingsets/train_regular_pubqc130K/image_train.pickle', 'rb') as f:\n",
    "    X_smiles_train0, SMILES_train0, y_train00 = pickle.load(f)\n",
    "    \n",
    "with open('./../data/trainingsets/train_regular_pubqc130K/image_test.pickle', 'rb') as f:\n",
    "    X_smiles_val0, SMILES_val0, y_val00 = pickle.load(f)\n",
    "\n",
    "with open('./../data/trainingsets/train_regular_pubqc130K/tokenizer.pickle', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "tokenizer[0] = ' '\n",
    "with open('./../data/trainingsets/train_regular_pubqc130K/tokenizer_object.pickle', 'rb') as f:\n",
    "    tokenizer_ = pickle.load(f)\n",
    "\n",
    "with open('./../data/trainingsets/image.pickle', 'rb') as f:\n",
    "    X_smiles000, SMILES00, gan_train000 = pickle.load(f)\n",
    "\n",
    "print (X_smiles_train0.shape)\n",
    "print (X_smiles_val0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35da8a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case of reducing the number of samples\n",
    "# subsampling\n",
    "idx = np.random.choice(len(y_train00), int(len(y_train00) * 1), replace = False)\n",
    "X_smiles_train, SMILES_train, y_train0 = (X_smiles_train0[idx], SMILES_train0[idx], y_train00[idx])\n",
    "\n",
    "idx = np.random.choice(len(y_val00), int(len(y_val00) * 1), replace = False)\n",
    "X_smiles_val, SMILES_val, y_val0 = (X_smiles_val0[idx], SMILES_val0[idx], y_val00[idx])\n",
    "\n",
    "print (X_smiles_train.shape)\n",
    "print (X_smiles_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5cffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (min(y_train00))\n",
    "print (max(y_train00))\n",
    "print (min(y_val0))\n",
    "print (max(y_val0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5288e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardized between 0 and 11\n",
    "gap_min = 0\n",
    "gap_max = 15\n",
    "\n",
    "y_val = NormalizeData(y_val0, min_data=gap_min, max_data=gap_max)\n",
    "y_train = NormalizeData(y_train0, min_data=gap_min, max_data=gap_max)\n",
    "y_gantrain = NormalizeData(gan_train000, min_data=gap_min, max_data=gap_max)\n",
    "\n",
    "print (max(y_val))\n",
    "print (max(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaed59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "ax.tick_params(axis='both', length=4, width=2, colors='black', grid_alpha=0, labelsize=15)\n",
    "[i.set_linewidth(2) for i in ax.spines.values()]\n",
    "plt.xlabel('HOMO-LUMO gap (eV)', fontname='Arial', fontweight = 'bold', fontsize=15)\n",
    "plt.ylabel('% of samples', fontname='Arial', fontweight = 'bold', fontsize=15)\n",
    "sns.histplot (y_train0, color='red', label='train', stat='percent', kde=True, bins=50)\n",
    "sns.histplot (y_val0, color='blue', label='test', stat='percent', kde=True, bins=50, alpha=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('gap_test_train.jpeg', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55edf674",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" models definition and extracting pretrained encoder and decoder \"\"\"\n",
    "encoder = load_model('./../data/nns/keep/encoder.h5')\n",
    "decoder = load_model('./../data/nns/keep/decoder.h5')\n",
    "\n",
    "class Config:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.Filters = [256, 128, 64]\n",
    "        self.genFilters = [128, 128, 128]\n",
    "        self.upFilters = [(2, 2), (2, 2), (2, 2)]\n",
    "        \n",
    "config = Config()\n",
    "\n",
    "## Generator \n",
    "z = Input(shape = (128, ))\n",
    "y = Input(shape = (1, ))\n",
    "\n",
    "h = Concatenate(axis = 1)([z, y])\n",
    "h = Dense(1 * 1 * 128)(h)\n",
    "R1 = Reshape([1, 1, 128])(h)\n",
    "R2 = Reshape([1, 1, 128])(h)\n",
    "\n",
    "for i in range(3):\n",
    "    R1 = UpSampling2D(size = config.upFilters[i])(R1)\n",
    "    C1 = Conv2D(filters = config.genFilters[i], \n",
    "               kernel_size = 2, \n",
    "               strides = 1, \n",
    "               padding = 'same')(R1)\n",
    "    B1 = BatchNormalization()(C1)\n",
    "    R1 = LeakyReLU(alpha=0.2)(B1)\n",
    "\n",
    "for i in range(3):\n",
    "    R2 = UpSampling2D(size = config.upFilters[i])(R2)\n",
    "    C2 = Conv2D(filters = config.genFilters[i], \n",
    "               kernel_size = 2, \n",
    "               strides = 1, \n",
    "               padding = 'same')(R2)\n",
    "    B2 = BatchNormalization()(C2)\n",
    "    R2 = LeakyReLU(alpha=0.2)(B2)\n",
    "    \n",
    "R1 = Conv2D(1,\n",
    "            kernel_size = 3,\n",
    "            strides = 1,\n",
    "            padding = 'valid',\n",
    "            activation = 'tanh')(R1)\n",
    "R2 = Conv2D(1,\n",
    "            kernel_size = 3,\n",
    "            strides = 1,\n",
    "            padding = 'valid',\n",
    "            activation = 'tanh')(R2)\n",
    "\n",
    "generator = Model([z, y], [R1, R2])\n",
    "\n",
    "## Discriminator \n",
    "inp1 = Input(shape = [6, 6, 1])\n",
    "inp2 = Input(shape = [6, 6, 1])\n",
    "\n",
    "X1 = Concatenate()([inp1, inp2])\n",
    "X = Flatten()(X1)\n",
    "y2 = Concatenate(axis = 1)([X, y])\n",
    "for i in range(3):\n",
    "\t\ty2 = Dense(64, activation = 'relu')(y2)\n",
    "\t\ty2 = LeakyReLU(alpha = 0.2)(y2)\n",
    "\t\ty2 = Dropout(0.2)(y2)\n",
    "\n",
    "O_dis = Dense(1, activation = 'sigmoid')(y2)\n",
    "discriminator = Model([inp1, inp2, y], O_dis)\n",
    "discriminator.compile(loss = 'binary_crossentropy', optimizer = Adam(lr = 5e-5, beta_1 = 0.5))\n",
    "print (discriminator.summary()) \n",
    "\n",
    "## Regressor\n",
    "inp1 = Input(shape = [6, 6, 1])\n",
    "inp2 = Input(shape = [6, 6, 1])\n",
    "\n",
    "yr = Concatenate()([inp1, inp2])\n",
    "\n",
    "tower0 = Conv2D(64, 1, padding = 'same')(yr)\n",
    "tower1 = Conv2D(64, 1, padding = 'same')(yr)\n",
    "tower1 = Conv2D(64, 3, padding = 'same')(tower1)\n",
    "tower2 = Conv2D(32, 1, padding = 'same')(yr)\n",
    "tower2 = Conv2D(32, 5, padding = 'same')(tower2)\n",
    "tower3 = MaxPooling2D(3, 1, padding = 'same')(yr)\n",
    "tower3 = Conv2D(32, 1, padding = 'same')(tower3)\n",
    "h = Concatenate()([tower0, tower1, tower2, tower3])\n",
    "h = ReLU()(h)\n",
    "h = MaxPooling2D(2, 1, padding = 'same')(h)\n",
    "\n",
    "for i in range(6):\n",
    "    tower0 = Conv2D(64, 1, padding = 'same')(h)\n",
    "    tower1 = Conv2D(64, 1, padding = 'same')(h)\n",
    "    tower1 = Conv2D(64, 3, padding = 'same')(tower1)\n",
    "    tower2 = Conv2D(32, 1, padding = 'same')(h)\n",
    "    tower2 = Conv2D(32, 5, padding = 'same')(tower2)\n",
    "    tower3 = MaxPooling2D(3, 1, padding = 'same')(h)\n",
    "    tower3 = Conv2D(32, 1, padding = 'same')(tower3)\n",
    "    h = Concatenate()([tower0, tower1, tower2, tower3])\n",
    "    h = ReLU()(h)\n",
    "    if i % 2 == 0 and i != 0:\n",
    "        h = MaxPooling2D(2, 1, padding = 'same')(h)\n",
    "h = BatchNormalization()(h)\n",
    "\n",
    "yr = Flatten()(h)\n",
    "o = Dropout(0.2)(yr)\n",
    "o = Dense(128)(o)\n",
    "o_reg = Dropout(0.2)(o)\n",
    "o_reg = Dense(1, activation = 'sigmoid')(o_reg)\n",
    "regressor = Model([inp1, inp2], o_reg)\n",
    "regressor_top = Model([inp1, inp2], o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b74e336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Regressor \n",
    "# latent vectors from trained Encoder, \n",
    "# last output of Encoder is concat. (O1, O2)\n",
    "train_atoms_embedding, train_bonds_embedding, _ = encoder.predict([X_smiles_train], verbose=0)\n",
    "atoms_embedding, bonds_embedding, _ = encoder.predict([X_smiles_train], verbose=0)\n",
    "atoms_val, bonds_val, _ = encoder.predict([X_smiles_val], verbose=0)\n",
    "\n",
    "# No training if the trained model is saved. \n",
    "try:\n",
    "    regressor = load_model('./../data/nns/keep/regressor_15max.h5')\n",
    "    regressor_top = load_model('./../data/nns/keep/regressor_top_15max.h5')\n",
    "    regressor.compile(loss = 'mse', optimizer = Adam(1e-6))\n",
    "    print (\".h5 was read\")\n",
    "except:\n",
    "    print (\"no .h5 available\")\n",
    "    regressor.compile(loss = 'mse', optimizer = Adam(1e-6))\n",
    "    pass\n",
    "    \n",
    "history = regressor.fit([atoms_embedding, bonds_embedding], \n",
    "              y_train,\n",
    "              validation_data = ([atoms_val,\n",
    "                                  bonds_val],\n",
    "                                 y_val),\n",
    "              batch_size = 256,\n",
    "              epochs = 1,\n",
    "              verbose = 1)\n",
    "    \n",
    "# Validating the regressor\n",
    "# Train\n",
    "pred_train = regressor.predict([atoms_embedding, bonds_embedding])\n",
    "pred_train0 = pred_train*(gap_max-gap_min)+gap_min\n",
    "print('Current R2 on Regressor for train data: {}'.format(r2_score(y_train0, pred_train0.reshape([-1]))))\n",
    "mse_train = mean_squared_error(y_train0, pred_train0.reshape([-1]))\n",
    "mae_train = mean_absolute_error(y_train0, pred_train0.reshape([-1]))\n",
    "\n",
    "# Test\n",
    "pred = regressor.predict([atoms_val, bonds_val])\n",
    "pred0 = pred*(gap_max-gap_min) + gap_min\n",
    "print('Current R2 on Regressor for test data: {}'.format(r2_score(y_val0, pred0.reshape([-1]))))\n",
    "mse_test = mean_squared_error (y_val0, pred0.reshape([-1]))\n",
    "mae_test = mean_absolute_error (y_val0, pred0.reshape([-1]))\n",
    "\n",
    "print ('Train MSE: {}, RMSE: {}, MAE: {}'.format (round(mse_train, 5), \n",
    "                                                  round(mse_train**0.5, 5), \n",
    "                                                  round(mae_train, 5)))\n",
    "print ('Test MSE: {}, RMSE: {}, MAE: {}'.format (round(mse_test, 5), \n",
    "                                                  round(mse_test**0.5, 5), \n",
    "                                                  round(mae_test, 5)))\n",
    "# Saving the currently trained models\n",
    "regressor.save('./../data/nns/regressor.h5')\n",
    "regressor_top.save('./../data/nns/regressor_top.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9cf345",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (np.max(pred0))\n",
    "print (np.max(y_train0))\n",
    "print (np.max(pred_train0))\n",
    "print (np.max(y_val0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9165cbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_pred_des = np.round (mean_absolute_error(pred0, y_val0), 4)\n",
    "print (\"MAE_pred_des\", MAE_pred_des)\n",
    "# Fractioned MAE, more normalized\n",
    "Fractioned_MAE_pred_des = 0\n",
    "for pred, true in zip(pred0, y_val0):\n",
    "        Fractioned_MAE_pred_des = Fractioned_MAE_pred_des +  abs(pred-true)/true\n",
    "Fractioned_MAE_pred_des = Fractioned_MAE_pred_des/(pred0.shape[0])\n",
    "print (\"MAEF_pred_des\", Fractioned_MAE_pred_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d52a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "plt.plot(list(range(len(history.history['loss']))), \n",
    "         history.history['loss'], label='Training loss', linewidth=3,) \n",
    "plt.plot(list(range(len(history.history['val_loss']))), \n",
    "         history.history['val_loss'], label='Validation loss', linewidth=3,) \n",
    "\n",
    "ax.set_xlabel('Epochs', fontsize='20', fontname='Arial', fontweight='bold', labelpad=5)\n",
    "ax.set_ylabel('Loss', fontsize='20', fontname='Arial', fontweight='bold', labelpad=5)\n",
    "\n",
    "ax.tick_params(direction='out', length=5, width=3, colors='black', grid_alpha=1, labelsize='18')\n",
    "\n",
    "[i.set_linewidth(2) for i in ax.spines.values()]\n",
    "#plt.ylim(0, 12)\n",
    "#plt.xticks((1, 3, 5, 7, 9,  11));\n",
    "#plt.yticks((1, 3, 5, 7, 9,  11));\n",
    "plt.title('Regressor loss', fontsize=15, fontname='Arial', fontweight='bold', pad=10)\n",
    "plt.legend(fontsize=15) \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"R_loss_0_100.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360345c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "plt.rcParams[\"legend.markerscale\"] = 10\n",
    "plt.scatter (y_train0, pred_train0, color='red', label='Train', alpha=0.6, s=0.05)\n",
    "plt.scatter ( y_val0, pred0, color='blue', label='Test', alpha=0.6, s=0.05)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "ax.set_xlabel('DFT gap (eV)', fontsize='20', fontname='Arial', fontweight='bold', labelpad=5)\n",
    "ax.set_ylabel('Pred. gap (eV)', fontsize='20', fontname='Arial', fontweight='bold', labelpad=5)\n",
    "\n",
    "ax.tick_params(direction='out', length=5, width=3, colors='black', \n",
    "               grid_alpha=1, labelsize='18')\n",
    "\n",
    "[i.set_linewidth(3) for i in ax.spines.values()]\n",
    "leg = plt.legend(title='Train: R$^2$={}, MAE={} \\nTest: R$^2$={}, MAE={}'.\\\n",
    "           format(round(r2_score(y_train0, pred_train0.reshape([-1])), 2), \n",
    "                  round (mae_train, 2),\n",
    "                  round (r2_score(y_val0, pred0.reshape([-1])), 2), \n",
    "                  round (mae_test, 2), ), framealpha=0, title_fontsize=15)\n",
    "leg._legend_box.align = \"left\"\n",
    "plt.xlim(0, 12)\n",
    "plt.ylim(0, 12)\n",
    "plt.xticks((1, 3, 5, 7, 9,  11));\n",
    "plt.yticks((1, 3, 5, 7, 9,  11));\n",
    "plt.plot([0, 12], [0, 12], '--k', )#color='black')\n",
    "plt.tight_layout()\n",
    "plt.savefig('regressor_train_test.jpeg', dpi=300)\n",
    "plt.rcParams[\"legend.markerscale\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d457c870",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combined model \n",
    "def build_combined(z, y,\n",
    "                   regressor,\n",
    "                   regressor_top,\n",
    "                   discriminator,\n",
    "                   encoder,\n",
    "                   decoder):\n",
    "    discriminator.trainable = False\n",
    "    regressor_top.trainable = False\n",
    "    regressor.trainable = False\n",
    "    encoder.trainable = False\n",
    "    decoder.trainable = False\n",
    "    \n",
    "    atoms_emb, bonds_emb = generator([z, y])\n",
    "    dec_embedding = Concatenate()([atoms_emb, bonds_emb])\n",
    "    \n",
    "    softmax_smiles, _ = decoder([dec_embedding])\n",
    "    argmax_smiles = argmax (softmax_smiles, axis=2)\n",
    "    argmax_smiles = Reshape([40])(argmax_smiles)\n",
    "    smiles = one_hot(argmax_smiles, depth=27)\n",
    "    smiles = Reshape([40, 27, 1])(smiles)\n",
    "    latent_encoder_atom, latent_encoder_bond, _ = encoder ([smiles])\n",
    "    \n",
    "    y_pred = regressor([latent_encoder_atom, latent_encoder_bond])\n",
    "    valid = discriminator([atoms_emb, bonds_emb, y])\n",
    "    #print ('valid from comb', valid)\n",
    "\n",
    "    combined = Model([z, y], [valid, y_pred])\n",
    "\n",
    "    combined.compile(loss = ['binary_crossentropy',\n",
    "                             'mse'], \n",
    "                     loss_weights = [0.01, 25.0], \n",
    "                     optimizer = Adam(5e-6, beta_1 = 0.2))\n",
    "    \n",
    "    return combined\n",
    "\n",
    "combined = build_combined(z, y,\n",
    "                          regressor,\n",
    "                          regressor_top,\n",
    "                          discriminator,\n",
    "                          encoder,\n",
    "                          decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c2af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Training RCGAN \"\"\"\n",
    "# loading pretrained models\n",
    "#regressor = load_model    ('./../data/nns/regressor.h5')\n",
    "#regressor_top = load_model('./../data/nns/regressor_top.h5')\n",
    "#generator = load_model    ('./../data/nns/keep/generator.h5')\n",
    "#discriminator = load_model ('./../data/nns/keep/discriminator.h5')\n",
    "#combined = load_model ('./../data/nns/combined.h5')\n",
    "\n",
    "regressor_top.trainable = False\n",
    "regressor.trainable = False\n",
    "\n",
    "# SMILES related information\n",
    "max_gen_atoms = 9\n",
    "bond_max = 9\n",
    "MAX_NB_WORDS = 27\n",
    "MAX_SEQUENCE_LENGTH = 40\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 1024\n",
    "batches = y_train0.shape[0] // batch_size\n",
    "threshold = 0.2 # defining accurate samples\n",
    "reinforce_n = 50 # 5*reinforce_n = fake sampling\n",
    "reinforce_sample = 1000 # how many samples generated for Reinforcement\n",
    "\n",
    "# variable for storing generated data\n",
    "G_Losses = []\n",
    "D_Losses = []\n",
    "R_Losses = []\n",
    "D_Losses_real = []\n",
    "D_Losses_fake = []\n",
    "\n",
    "for e in range(epochs):\n",
    "    start = time.time()\n",
    "    D_loss = []\n",
    "    G_loss = []\n",
    "    R_loss = []\n",
    "    D_loss_real = []\n",
    "    D_loss_fake = []\n",
    "    \n",
    "    for b in range(batches):\n",
    "        regressor_top.trainable = False\n",
    "        regressor.trainable = False\n",
    "\n",
    "        idx = np.arange(b * batch_size, (b + 1) * batch_size)\n",
    "        # rearrange the samples \n",
    "        idx = np.random.choice(idx, batch_size, replace = False)\n",
    "        \n",
    "        x_smiles0 = X_smiles000[idx] \n",
    "        batch_y = y_gantrain[idx]\n",
    "        \n",
    "        batch_z = np.random.normal(0, 1, size = (batch_size, 128))\n",
    "        \n",
    "        atoms_embedding, bonds_embedding, _ = encoder.predict([x_smiles0], verbose=0)\n",
    "        dec_embedding = np.concatenate([atoms_embedding, bonds_embedding], axis = -1)\n",
    "        \n",
    "        gen_atoms_embedding, gen_bonds_embedding = generator.predict([batch_z, batch_y], verbose=0)\n",
    "        \n",
    "        gen_dec_embedding = np.concatenate([gen_atoms_embedding, gen_bonds_embedding], axis = -1)\n",
    "        softmax_smiles = decoder.predict(gen_dec_embedding, verbose=0)[0]\n",
    "        \n",
    "        argmax_smiles = np.argmax(softmax_smiles, axis = 2)\n",
    "        smiles = to_categorical(argmax_smiles, num_classes=27)\n",
    "        SHAPE = list(smiles.shape) + [1]\n",
    "        smiles = smiles.reshape(SHAPE)\n",
    "        latent_encoder_atom, latent_encoder_bond, _ = encoder.predict([smiles], verbose=0)\n",
    "        gen_pred = regressor.predict([latent_encoder_atom, latent_encoder_bond], verbose=0).reshape([-1])\n",
    "        \n",
    "        regressor.trainable = True\n",
    "        r_loss = regressor.train_on_batch([atoms_embedding, bonds_embedding], batch_y)\n",
    "        R_loss.append(r_loss)\n",
    "        regressor.trainable = False\n",
    "\n",
    "        discriminator.trainable = True\n",
    "\n",
    "        d = 3\n",
    "        for _ in range(d):\n",
    "            d_loss_real = discriminator.train_on_batch([atoms_embedding, bonds_embedding, batch_y],\n",
    "                                                       [0.9 * np.ones((batch_size, 1))])\n",
    "            d_loss_fake = discriminator.train_on_batch([gen_atoms_embedding, gen_bonds_embedding, batch_y],\n",
    "                                                       [np.zeros((batch_size, 1))]) \n",
    "\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        D_loss.append(d_loss)\n",
    "        D_loss_real.append (d_loss_real)\n",
    "        D_loss_fake.append (d_loss_fake)\n",
    "        discriminator.trainable = False\n",
    "        \n",
    "        regressor_top.trainable = False\n",
    "        regressor.trainable = False\n",
    "\n",
    "        g_loss = combined.train_on_batch([batch_z, batch_y], [0.9 * np.ones((batch_size, 1)), batch_y])\n",
    "        G_loss.append(g_loss[0])\n",
    "    \n",
    "    D_Losses.append(np.mean(D_loss))\n",
    "    D_Losses_real.append(np.mean(D_loss_real))\n",
    "    D_Losses_fake.append(np.mean(D_loss_fake))\n",
    "    G_Losses.append(np.mean(G_loss))\n",
    "    R_Losses.append(np.mean(R_loss))\n",
    "    \n",
    "    print('====')\n",
    "    print('Current epoch: {}/{}'.format((e + 1), epochs))\n",
    "    print ('D Loss Real: {}'.format(np.mean(D_loss_real)))\n",
    "    print ('D Loss Fake: {}'.format(np.mean(D_loss_fake)))\n",
    "    print('D Loss: {}'.format(np.mean(D_loss)))\n",
    "    print('G Loss: {}'.format(np.mean(G_loss)))\n",
    "    print('R Loss: {}'.format(np.mean(R_loss)))\n",
    "    print('====')\n",
    "    print()\n",
    "\n",
    "    \n",
    "    # Reinforcement\n",
    "    gen_error = []\n",
    "    gen_smiles = []\n",
    "    gen_valid_smiles = []\n",
    "    gen_X_atoms = []\n",
    "    gen_X_bonds = []\n",
    "    predcv_AE_latent = []\n",
    "    embeddings = []\n",
    "    sample_ys = []\n",
    "    valid_smiles_index = []\n",
    "    for _ in range(reinforce_sample):\n",
    "        sample_y = np.random.uniform(1, 11, size = [1, ])\n",
    "        sample_y = np.round(sample_y, 4)\n",
    "        sample_y = (sample_y - gap_min) / (gap_max - gap_min)\n",
    "        sample_ys.append(sample_y)\n",
    "\n",
    "        sample_z = np.random.normal(0, 1, size = (1, 128))\n",
    "\n",
    "        sample_atoms_embedding, sample_bonds_embedding = generator.predict([sample_z, sample_y], verbose=0)\n",
    "        embeddings.append((sample_atoms_embedding, sample_bonds_embedding))\n",
    "        \n",
    "        dec_embedding = np.concatenate([sample_atoms_embedding, sample_bonds_embedding], axis = -1)\n",
    "        softmax_smiles = decoder.predict(dec_embedding, verbose=0)[0]\n",
    "        argmax_smiles = np.argmax(softmax_smiles, axis = 2).reshape([-1])\n",
    "        smiles = to_categorical(argmax_smiles, num_classes=27)\n",
    "        SHAPE = [1] + list(smiles.shape) + [1]\n",
    "        smiles = smiles.reshape(SHAPE)\n",
    "        c_smiles = ''\n",
    "        for s in argmax_smiles:\n",
    "            c_smiles += tokenizer[s]\n",
    "        c_smiles = c_smiles.rstrip()\n",
    "        \n",
    "        gen_smiles.append(c_smiles)\n",
    "        latent_encoder_atom, latent_encoder_bond, _ = encoder.predict([smiles], verbose=0)\n",
    "        reg_pred = regressor.predict([latent_encoder_atom, latent_encoder_bond], verbose=0)\n",
    "        \n",
    "        pred, desire = reg_pred[0][0], sample_y[0]\n",
    "        gen_error.append(round (np.abs((pred - desire) / (pred)), 5)) #!!!!!!!!!!!!! chenge it to desire\n",
    "\n",
    "        \n",
    "    gen_error = np.asarray(gen_error)\n",
    "    # two validity defined: \n",
    "    ## without sanitizing: valid0, sanitized=valid  \n",
    "    valid = 0\n",
    "    valid0 = 0\n",
    "    idx_ = []\n",
    "    idx0_ = []\n",
    "    for iter_, smiles in enumerate(gen_smiles):\n",
    "        if ' ' in smiles[:-1]:\n",
    "            continue\n",
    "        m  = Chem.MolFromSmiles(smiles[:-1], sanitize=True)\n",
    "        m0 = Chem.MolFromSmiles(smiles[:-1], sanitize=False)\n",
    "        if m0 is not None:\n",
    "            valid0 += 1\n",
    "            idx0_.append(iter_)\n",
    "        if m is not None:\n",
    "            valid += 1\n",
    "            idx_.append(iter_)\n",
    "            try:\n",
    "                gen_smiles [iter_] = Chem.MolToSmiles(m, canonical=True)\n",
    "                print (Chem.MolToSmiles(m, canonical=True))\n",
    "                print (\"gap_des\", sample_ys[iter_])\n",
    "                print (\"error\", gen_error[iter_])\n",
    "            except:\n",
    "                pass\n",
    "    idx_ = np.asarray(idx_)\n",
    "    idx0_ = np.asarray(idx0_)\n",
    "\n",
    "    validity = [gen_smiles[jj] for jj in idx0_ ]\n",
    "    validity = pd.DataFrame(validity)\n",
    "    validity = validity.drop_duplicates()\n",
    "\n",
    "    validity_sanitize = [gen_smiles[jj] for jj in idx_ ]\n",
    "    validity_sanitize = pd.DataFrame(validity_sanitize)\n",
    "    validity_sanitize = validity_sanitize.drop_duplicates()\n",
    "\n",
    "    if (e + 1) % 100 == 0:\n",
    "        reinforce_n += 10\n",
    "\n",
    "    # invalid smiles:\n",
    "    fake_indices1 = np.setdiff1d(np.arange(reinforce_sample), np.asarray(idx_))\n",
    "    fake_indices2 = np.intersect1d(np.where(gen_error > threshold)[0], idx_)\n",
    "    fake_indices = np.concatenate ((fake_indices1, fake_indices2))\n",
    "    fake_indices = np.random.choice(fake_indices, reinforce_n * 5, replace = False)\n",
    "\n",
    "    real_indices_ = np.intersect1d(np.where(gen_error <= threshold)[0], idx_)\n",
    "    sample_size =  len(real_indices_)\n",
    "    real_indices = np.random.choice(real_indices_, sample_size, replace = False)\n",
    "    \n",
    "    # Activating Reinforcement: hyperparameter\n",
    "    if e >= 5:\n",
    "        discriminator.trainable = True\n",
    "        regressor_top.trainable = False\n",
    "        regressor.trainable = False\n",
    "        for real_index in real_indices:\n",
    "            _ = discriminator.train_on_batch([embeddings[real_index][0], \n",
    "                                              embeddings[real_index][1], \n",
    "                                              sample_ys[real_index]],\n",
    "                                             [1 * np.ones((1, 1))])\n",
    "\n",
    "        for fake_index in fake_indices:\n",
    "            _ = discriminator.train_on_batch([embeddings[fake_index][0], \n",
    "                                              embeddings[fake_index][1] , \n",
    "                                              sample_ys[fake_index]],\n",
    "                                             [np.zeros((1, 1))])\n",
    "        discriminator.trainable = False\n",
    "\n",
    "    # ==== #\n",
    "    try:\n",
    "        print('Currently valid SMILES (No chemical_beauty and sanitize off): {}'.format(valid0))\n",
    "        print('Currently valid SMILES Unique (No chemical_beauty and sanitize off): {}'.format(len(validity)))\n",
    "        print('Currently valid SMILES Sanitized: {}'.format(valid))\n",
    "        print('Currently valid Unique SMILES Sanitized: {}'.format(len(validity_sanitize)))\n",
    "        print('Currently satisfying SMILES: {}'.format(len(real_indices_)))\n",
    "        print('Currently unique satisfying generation: {}'.format(len(np.unique(np.array(gen_smiles)[real_indices_]))))\n",
    "        print('====')\n",
    "        print()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if (e + 1) % 5 == 0:\n",
    "        plt.close()\n",
    "        fig, ax = plt.subplots(figsize = (12, 10))\n",
    "        ax.tick_params(axis='both', which='major', labelsize=30)\n",
    "        plt.plot(G_Losses, color='blue')\n",
    "        plt.plot(D_Losses, color='red')\n",
    "        plt.xlabel('epochs', fontsize=35)\n",
    "        plt.ylabel('loss', fontsize=35)\n",
    "        mpl.rcParams['axes.linewidth'] = 2.5\n",
    "        plt.legend(['G Loss', 'D Loss'], fontsize=30)\n",
    "        plt.savefig(\"G_D_losses{}.png\".format (e+1))\n",
    "    \n",
    "\n",
    "    n_unique = len(np.unique(np.array(gen_smiles)[real_indices_]))\n",
    "    n_valid = valid\n",
    "    end = time.time()\n",
    "    print (\"time for current epoch: \", (end - start))\n",
    "    tf.compat.v1.keras.backend.clear_session()\n",
    "\n",
    "with open('GAN_loss.pickle', 'wb') as f:\n",
    "    pickle.dump((G_Losses, D_Losses, R_Losses), f)\n",
    "\n",
    "# Saving the currently trained models\n",
    "#regressor.save('regressor.h5')\n",
    "#regressor_top.save('regressor_top.h5')\n",
    "generator.save('./../data/nns/generator_noreinf.h5')\n",
    "discriminator.save('./../data/nns/discriminator_noreinf.h5')\n",
    "combined.save('./../data/nns/combined.h5')\n",
    "\n",
    "p.start()\n",
    "p.join()\n",
    "tf.compat.v1.keras.backend.clear_session()\n",
    "print ('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e15d4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder = load_model('./../data/nns/keep/encoder.h5')\n",
    "decoder = load_model('./../data/nns/keep/decoder.h5')\n",
    "model = load_model('./../data/nns/keep/ae_model.h5')\n",
    "\n",
    "#regressor = load_model    ('./../data/nns/regressor.h5')\n",
    "#regressor_top = load_model('./../data/nns/regressor_top.h5')\n",
    "#generator = load_model    ('./../data/nns/generator.h5')\n",
    "#discriminator= load_model ('./../data/nns/discriminator.h5')\n",
    "\n",
    "pbar = ProgressBar()\n",
    "max = 0.3\n",
    "\n",
    "randS = []\n",
    "rsquaredS = []\n",
    "MAE_S = []\n",
    "less20RE_perS = []\n",
    "output_lenS = []\n",
    "mean_RE_S = []\n",
    "\n",
    "N = 50\n",
    "n_sample = 75\n",
    "gen_error = []\n",
    "gen_smiles = []\n",
    "sample_ys = []\n",
    "preds = []\n",
    "\n",
    "predss_can = []\n",
    "gen_atoms_embedding = []\n",
    "gen_bonds_embedding = []\n",
    "\n",
    "regressor_top.trainable = False\n",
    "regressor.trainable = False\n",
    "generator.trainable = False\n",
    "discriminator.trainable = False\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "pbar = ProgressBar()\n",
    "samples = np.random.uniform(1, 11, size=[n_sample, ])\n",
    "for sample in (pbar(samples)):\n",
    "    try:\n",
    "        sample_y = sample\n",
    "        sample_y = np.round(sample_y, 4)\n",
    "        sample_y = sample_y * np.ones([N, ])\n",
    "        sample_y_ = (sample_y - gap_min) / (gap_max - gap_min)\n",
    "        sample_z = np.random.normal(0, 1, size = (N, 128))\n",
    "\n",
    "        regressor_top.trainable = False\n",
    "        regressor.trainable = False\n",
    "        encoder.trainable = False\n",
    "        decoder.trainable = False\n",
    "\n",
    "        sample_atoms_embedding, sample_bonds_embedding = generator.predict([sample_z, sample_y_], verbose=0)\n",
    "        dec_embedding = np.concatenate([sample_atoms_embedding, sample_bonds_embedding], axis = -1)\n",
    "\n",
    "        softmax_smiles = decoder.predict(dec_embedding, verbose=0)[0]\n",
    "        argmax_smiles = np.argmax(softmax_smiles, axis = 2)\n",
    "        #print (argmax_smiles)\n",
    "\n",
    "        #print ('shape argmax_smiles', argmax_smiles.shape)\n",
    "        smiles = to_categorical(argmax_smiles, num_classes=27)\n",
    "        \n",
    "        SHAPE = list(smiles.shape) + [1] \n",
    "        \n",
    "        #print ('shape line 767', SHAPE) \n",
    "        smiles = smiles.reshape(SHAPE)\n",
    "\n",
    "        latent_encoder_atom, latent_encoder_bond, _ = encoder.predict([smiles], verbose=0)\n",
    "        pred = regressor.predict([latent_encoder_atom, latent_encoder_bond], verbose=0).reshape([-1])\n",
    "        pred = pred * (gap_max - gap_min) + gap_min\n",
    "\n",
    "        gen_errors = np.abs((pred - sample_y) / sample_y).reshape([-1])\n",
    "\n",
    "\n",
    "        smiles = decoder.predict(dec_embedding, verbose=0)[0]\n",
    "        #print(smiles)\n",
    "        smiles = np.argmax(smiles, axis = 2).reshape(smiles.shape[0], 40)\n",
    "        \n",
    "\n",
    "        generated_smiles = []\n",
    "        \n",
    "        for S in smiles:\n",
    "            c_smiles = ''\n",
    "            for s in S:\n",
    "                c_smiles += tokenizer[s]\n",
    "            c_smiles = c_smiles.rstrip()\n",
    "            #print (c_smiles)\n",
    "            generated_smiles.append(c_smiles)\n",
    "        generated_smiles = np.array(generated_smiles)\n",
    "        #generated_smiles = generated_smiles [accurate]\n",
    "        all_gen_smiles = []\n",
    "        idx = []\n",
    "        preds_can = []\n",
    "        for i, smiles in enumerate(generated_smiles):\n",
    "            all_gen_smiles.append(smiles[:-1])\n",
    "\n",
    "            if ' ' in smiles[:-1]:\n",
    "                continue\n",
    "            #m = Chem.MolFromSmiles(smiles[:-1], sanitize=False)\n",
    "            m = Chem.MolFromSmiles(smiles[:-1], sanitize=True)\n",
    "            if m is not None:\n",
    "                idx.append(i)\n",
    "                smiles_can = Chem.MolToSmiles(m, canonical=True)\n",
    "                smiles_can_dot = smiles_can + '.'\n",
    "                X_smiles0 = tokenizer_.texts_to_sequences([smiles_can_dot])\n",
    "                X_smiles1 = pad_sequences(X_smiles0, maxlen = 40, padding = 'post')\n",
    "                X_smiles2 = to_categorical(X_smiles1, num_classes=27)\n",
    "                latent_encoder_atom, latent_encoder_bond, _ = encoder.predict(X_smiles2, verbose=0)\n",
    "                pred_can = regressor.predict([latent_encoder_atom, latent_encoder_bond], verbose=0).reshape([-1])\n",
    "                pred_can = pred_can*15\n",
    "                preds_can.append(pred_can[0])\n",
    "\n",
    "\n",
    "        idx = np.array(idx)\n",
    "        all_gen_smiles = np.array(all_gen_smiles)\n",
    "        #print ('all gen smiels shape', all_gen_smiles.shape)\n",
    "        #print ('gen_errors shape', gen_errors.shape)\n",
    "        #print (idx)\n",
    "        gen_smiles.extend(list(all_gen_smiles[idx]))\n",
    "        gen_error.extend(list(gen_errors[idx]))\n",
    "        sample_ys.extend(list(sample_y[idx]))\n",
    "        gen_atoms_embedding.extend(sample_atoms_embedding[idx])\n",
    "        gen_bonds_embedding.extend(sample_bonds_embedding[idx])\n",
    "        preds.extend(list(pred[idx]))\n",
    "        predss_can.extend(list(preds_can))\n",
    "    except:\n",
    "        pass    \n",
    "\n",
    "\n",
    "output = {}\n",
    "\n",
    "for i, s in enumerate (gen_smiles):\n",
    "    ss = Chem.MolToSmiles(Chem.MolFromSmiles(s, sanitize=True), canonical=True)\n",
    "    gen_smiles[i] = ss\n",
    "\n",
    "output['SMILES'] = gen_smiles\n",
    "output['des_gap'] = sample_ys\n",
    "# More accurate for regressor to predict gap from canonical SMILES\n",
    "output['pred_gap'] = predss_can\n",
    "#output['Err_pred_des'] = gen_error\n",
    "output['Err_pred_des'] = [abs(i- j)/i for i, j in zip(output['des_gap'], output['pred_gap'])]\n",
    "output = pd.DataFrame(output)\n",
    "output.reset_index(drop = True, inplace = True)\n",
    "output.to_csv ('./../experiments/regular/Initial_training.csv', index=False)\n",
    "\n",
    "N = len(predss_can)\n",
    "# Explained Variance R2 from sklearn.metrics.explained_variance_score\n",
    "explained_variance_R2_pred_des = explained_variance_score(output['des_gap'], output['pred_gap'])\n",
    "print (\"explained_varice_R2_pred_des\", explained_variance_R2_pred_des)\n",
    "rsquared = np.round (r2_score (output['des_gap'], output['pred_gap']), 4)\n",
    "print (\"r squared r**2\", rsquared)\n",
    "\n",
    "# mean absolute error \n",
    "MAE_pred_des = np.round (mean_absolute_error(output['pred_gap'], output['des_gap']), 4)\n",
    "print (\"MAE_pred_des\", MAE_pred_des)\n",
    "# Fractioned MAE, more normalized\n",
    "Fractioned_MAE_pred_des = 0\n",
    "for pred, des in zip(output['pred_gap'], output['des_gap']):\n",
    "    Fractioned_MAE_pred_des = Fractioned_MAE_pred_des +  abs(des-pred)/des\n",
    "Fractioned_MAE_pred_des = Fractioned_MAE_pred_des/N\n",
    "#print (\"Fractioned MAE_pred_des\", Fractioned_MAE_pred_des)\n",
    "\n",
    "# root mean squared error (RMSE), sqrt(sklearn ouputs MSE)\n",
    "RMSE_pred_des = mean_squared_error(output['pred_gap'], output['des_gap'])**0.5\n",
    "\n",
    "Fractioned_RMSE_pred_des = 0\n",
    "for pred, des in zip(output['pred_gap'], output['des_gap']):\n",
    "    Fractioned_RMSE_pred_des = Fractioned_RMSE_pred_des + ((des-pred)/des)**2\n",
    "Fractioned_RMSE_pred_des = (Fractioned_RMSE_pred_des/N)**0.5\n",
    "output2 = output.drop_duplicates(['SMILES'])\n",
    "output2.reset_index(drop = True, inplace = True)\n",
    "output2.to_csv('./../experiments/regular/Initial_training_nodub.csv', index = False)\n",
    "\n",
    "less20RE_per = np.round ((sum(output['Err_pred_des'] <= 0.2) / output['Err_pred_des'].shape[0]), 4)\n",
    "print ('% < 20 RE', less20RE_per)\n",
    "output_len = len(output)\n",
    "explained_variance_R2_pred_des = explained_variance_score(output['des_gap'], output['pred_gap'])\n",
    "#print (\"explained_varice_R2_pred_des\", explained_variance_R2_pred_des)\n",
    "mean_RE = np.round (np.mean (output['Err_pred_des']), 4)\n",
    "print ('RE mean', mean_RE)\n",
    "tf.compat.v1.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878e7afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single target value\n",
    "encoder = load_model('./../data/nns/keep/encoder.h5')\n",
    "decoder = load_model('./../data/nns/keep/decoder.h5')\n",
    "\n",
    "regressor = load_model    ('./../data/nns/keep/regressor.h5')\n",
    "regressor_top = load_model('./../data/nns/keep/regressor_top.h5')\n",
    "generator = load_model    ('./../data/nns/keep/generator.h5')\n",
    "discriminator= load_model ('./../data/nns/keep/discriminator.h5')\n",
    "\n",
    "pbar = ProgressBar()\n",
    "max = 0.3\n",
    "\n",
    "randS = []\n",
    "rsquaredS = []\n",
    "MAE_S = []\n",
    "less20RE_perS = []\n",
    "output_lenS = []\n",
    "mean_RE_S = []\n",
    "for rand in pbar(range (28, 29)):  \n",
    "    N = 50000\n",
    "    n_sample = 1\n",
    "    gen_error = []\n",
    "    gen_smiles = []\n",
    "    sample_ys = []\n",
    "    preds = []\n",
    "  \n",
    "    predss_can = []\n",
    "    gen_atoms_embedding = []\n",
    "    gen_bonds_embedding = []\n",
    "\n",
    "    regressor_top.trainable = False\n",
    "    regressor.trainable = False\n",
    "    generator.trainable = False\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    np.random.seed(rand)\n",
    "\n",
    "    pbar = ProgressBar()\n",
    "    samples = np.random.uniform(1, 11, size=[n_sample, ])\n",
    "    for i, hc in (enumerate(samples)):\n",
    "        try:\n",
    "            # get it back to original of s_min to s_max\n",
    "            #sample_y = np.random.uniform(0, 10.7, size=[1,])\n",
    "            sample_y = hc\n",
    "            #print (sample_y)\n",
    "            sample_y = np.round(sample_y, 4)\n",
    "            sample_y = sample_y * np.ones([N, ])\n",
    "            sample_y_ = (sample_y - gap_min) / (gap_max - gap_min)\n",
    "            sample_z = np.random.normal(0, 1, size = (N, 128))\n",
    "\n",
    "            regressor_top.trainable = False\n",
    "            regressor.trainable = False\n",
    "            encoder.trainable = False\n",
    "            decoder.trainable = False\n",
    "\n",
    "            sample_atoms_embedding, sample_bonds_embedding = generator.predict([sample_z, sample_y_], verbose=0)\n",
    "            dec_embedding = np.concatenate([sample_atoms_embedding, sample_bonds_embedding], axis = -1)\n",
    "\n",
    "            softmax_smiles = decoder.predict(dec_embedding, verbose=0)[0]\n",
    "            argmax_smiles = np.argmax(softmax_smiles, axis = 2)\n",
    "            #print (argmax_smiles)\n",
    "\n",
    "            #print ('shape argmax_smiles', argmax_smiles.shape)\n",
    "            smiles = to_categorical(argmax_smiles, num_classes=27)\n",
    "            \n",
    "            SHAPE = list(smiles.shape) + [1] \n",
    "            \n",
    "            #print ('shape line 767', SHAPE) \n",
    "            smiles = smiles.reshape(SHAPE)\n",
    "\n",
    "            latent_encoder_atom, latent_encoder_bond, _ = encoder.predict([smiles], verbose=0)\n",
    "            pred = regressor.predict([latent_encoder_atom, latent_encoder_bond], verbose=0).reshape([-1])\n",
    "            pred = pred * (gap_max - gap_min) + gap_min\n",
    "\n",
    "            gen_errors = np.abs((pred - sample_y) / sample_y).reshape([-1])\n",
    "\n",
    "\n",
    "            smiles = decoder.predict(dec_embedding, verbose=0)[0]\n",
    "            #print(smiles)\n",
    "            smiles = np.argmax(smiles, axis = 2).reshape(smiles.shape[0], 40)\n",
    "            \n",
    "\n",
    "            generated_smiles = []\n",
    "            \n",
    "            for S in smiles:\n",
    "                c_smiles = ''\n",
    "                for s in S:\n",
    "                    c_smiles += tokenizer[s]\n",
    "                c_smiles = c_smiles.rstrip()\n",
    "                #print (c_smiles)\n",
    "                generated_smiles.append(c_smiles)\n",
    "            generated_smiles = np.array(generated_smiles)\n",
    "            #generated_smiles = generated_smiles [accurate]\n",
    "            all_gen_smiles = []\n",
    "            idx = []\n",
    "            preds_can = []\n",
    "            for i, smiles in enumerate(generated_smiles):\n",
    "                all_gen_smiles.append(smiles[:-1])\n",
    "\n",
    "                if ' ' in smiles[:-1]:\n",
    "                    continue\n",
    "                #m = Chem.MolFromSmiles(smiles[:-1], sanitize=False)\n",
    "                m = Chem.MolFromSmiles(smiles[:-1], sanitize=True)\n",
    "                if m is not None:\n",
    "                    idx.append(i)\n",
    "                    smiles_can = Chem.MolToSmiles(m, canonical=True)\n",
    "                    smiles_can_dot = smiles_can + '.'\n",
    "                    X_smiles0 = tokenizer_.texts_to_sequences([smiles_can_dot])\n",
    "                    X_smiles1 = pad_sequences(X_smiles0, maxlen = 40, padding = 'post')\n",
    "                    X_smiles2 = to_categorical(X_smiles1, num_classes=27)\n",
    "                    latent_encoder_atom, latent_encoder_bond, _ = encoder.predict(X_smiles2, verbose=0)\n",
    "                    pred_can = regressor.predict([latent_encoder_atom, latent_encoder_bond], verbose=0).reshape([-1])\n",
    "                    pred_can = pred_can*11\n",
    "                    preds_can.append(pred_can[0])\n",
    "\n",
    "\n",
    "            idx = np.array(idx)\n",
    "            all_gen_smiles = np.array(all_gen_smiles)\n",
    "            #print ('all gen smiels shape', all_gen_smiles.shape)\n",
    "            #print ('gen_errors shape', gen_errors.shape)\n",
    "            #print (idx)\n",
    "            gen_smiles.extend(list(all_gen_smiles[idx]))\n",
    "            gen_error.extend(list(gen_errors[idx]))\n",
    "            sample_ys.extend(list(sample_y[idx]))\n",
    "            gen_atoms_embedding.extend(sample_atoms_embedding[idx])\n",
    "            gen_bonds_embedding.extend(sample_bonds_embedding[idx])\n",
    "            preds.extend(list(pred[idx]))\n",
    "            predss_can.extend(list(preds_can))\n",
    "        except:\n",
    "            #print('Did not discover SMILES for HC: {}'.format(sample_y))\n",
    "            pass    \n",
    "\n",
    "\n",
    "    output = {}\n",
    "\n",
    "    for i, s in enumerate (gen_smiles):\n",
    "        ss = Chem.MolToSmiles(Chem.MolFromSmiles(s, sanitize=True), canonical=True)\n",
    "        gen_smiles[i] = ss\n",
    "\n",
    "    output['SMILES'] = gen_smiles\n",
    "    output['des_gap'] = sample_ys\n",
    "    # More accurate for regressor to predict gap from canonical SMILES\n",
    "    output['pred_gap'] = predss_can\n",
    "    #output['Err_pred_des'] = gen_error\n",
    "    output['Err_pred_des'] = [abs(i- j)/i for i, j in zip(output['des_gap'], output['pred_gap'])]\n",
    "    output = pd.DataFrame(output)\n",
    "    output.reset_index(drop = True, inplace = True)\n",
    "    output.to_csv ('./../experiments/regular/Initial_training.csv', index=False)\n",
    "\n",
    "    ## Statistics  (# pred=True value, Des=prediction)\n",
    "    # total # of samples\n",
    "    N = len(predss_can)\n",
    "    print ('random seed', rand)\n",
    "\n",
    "    # Explained Variance R2 from sklearn.metrics.explained_variance_score\n",
    "    explained_variance_R2_pred_des = explained_variance_score(output['des_gap'], output['pred_gap'])\n",
    "    print (\"explained_varice_R2_pred_des\", explained_variance_R2_pred_des)\n",
    "    rsquared = np.round (r2_score (output['des_gap'], output['pred_gap']), 4)\n",
    "    print (\"r squared r**2\", rsquared)\n",
    "\n",
    "    # mean absolute error \n",
    "    MAE_pred_des = np.round (mean_absolute_error(output['pred_gap'], output['des_gap']), 4)\n",
    "    print (\"MAE_pred_des\", MAE_pred_des)\n",
    "    # Fractioned MAE, more normalized\n",
    "    Fractioned_MAE_pred_des = 0\n",
    "    for pred, des in zip(output['pred_gap'], output['des_gap']):\n",
    "        Fractioned_MAE_pred_des = Fractioned_MAE_pred_des +  abs(des-pred)/des\n",
    "    Fractioned_MAE_pred_des = Fractioned_MAE_pred_des/N\n",
    "    #print (\"Fractioned MAE_pred_des\", Fractioned_MAE_pred_des)\n",
    "\n",
    "    # root mean squared error (RMSE), sqrt(sklearn ouputs MSE)\n",
    "    RMSE_pred_des = mean_squared_error(output['pred_gap'], output['des_gap'])**0.5\n",
    "    #print (\"RMSE_pred_des\", RMSE_pred_des)\n",
    "\n",
    "    Fractioned_RMSE_pred_des = 0\n",
    "    for pred, des in zip(output['pred_gap'], output['des_gap']):\n",
    "        Fractioned_RMSE_pred_des = Fractioned_RMSE_pred_des + ((des-pred)/des)**2\n",
    "    Fractioned_RMSE_pred_des = (Fractioned_RMSE_pred_des/N)**0.5\n",
    "    #print (\"Fractioned_RMSE_pred_des\", Fractioned_RMSE_pred_des)\n",
    "\n",
    "    # do not drop duplicate\n",
    "    output2 = output.drop_duplicates(['SMILES'])\n",
    "    output2.reset_index(drop = True, inplace = True)\n",
    "    output2.to_csv('./../experiments/regular/Initial_training_nodub.csv', index = False)\n",
    "    \"\"\"with open('gen_pickles.pickle', 'wb') as f:\n",
    "        pickle.dump(gen_unique_pickles, f)\n",
    "    \"\"\"\n",
    "    #print ('% < 20 RE NODUP', sum (output2['Err_pred_des'] < 0.2) / output2['Err_pred_des'].shape[0])\n",
    "    less20RE_per = np.round ((sum(output['Err_pred_des'] <= 0.2) / output['Err_pred_des'].shape[0]), 4)\n",
    "    print ('% < 20 RE', less20RE_per)\n",
    "    output_len = len(output)\n",
    "    explained_variance_R2_pred_des = explained_variance_score(output['des_gap'], output['pred_gap'])\n",
    "    #print (\"explained_varice_R2_pred_des\", explained_variance_R2_pred_des)\n",
    "    mean_RE = np.round (np.mean (output['Err_pred_des']), 4)\n",
    "    print ('RE mean', mean_RE)\n",
    "\n",
    "    randS.append(rand)\n",
    "    rsquaredS.append(rsquared)\n",
    "    MAE_S.append(MAE_pred_des)\n",
    "    less20RE_perS.append(less20RE_per)\n",
    "    mean_RE_S.append(mean_RE)\n",
    "    output_lenS.append(output_len)\n",
    "    print (output_lenS)\n",
    "\n",
    "    if rsquared>max:\n",
    "        good_rand = rand\n",
    "        max = rsquared\n",
    "        best_r2 = rsquared\n",
    "        print ('best r2', best_r2)\n",
    "        print ('best random seed', good_rand)\n",
    "    \n",
    "    tf.compat.v1.keras.backend.clear_session()\n",
    "\n",
    "params = {}\n",
    "params ['rand'] = randS\n",
    "params ['r2'] = rsquaredS\n",
    "params ['MAE'] = MAE_S\n",
    "params ['less20RE_per'] = less20RE_perS\n",
    "params ['Average_RE'] = mean_RE_S\n",
    "params ['total_valid'] = output_lenS\n",
    "params = pd.DataFrame(params)\n",
    "params.reset_index(drop = True, inplace = True)\n",
    "params.to_csv ('./gen_params.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b185e634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = pd.read_csv('./../experiments/regular/Single_target/single_target.csv')\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "sns.distplot(output['pred_gap'], bins=15,)\n",
    "plt.plot([output['des_gap'][0], output['des_gap'][0]], [0, 0.35], \n",
    "         label='Targ. $E_{gap}$: 8.29 (eV)')\n",
    "plt.legend()\n",
    "plt.xlim(0, 12)\n",
    "np.mean (output['pred_gap'])\n",
    "[i.set_linewidth(2) for i in ax.spines.values()]\n",
    "\n",
    "\n",
    "ax.tick_params(axis='both', direction='out', length=5, width=3, colors='black', \n",
    "               grid_alpha=0, labelsize='18')\n",
    "\n",
    "\n",
    "plt.xlabel(r'Pred. $E_{gap}$ (eV)', fontsize=18, \n",
    "           fontname='Arial', fontweight=\"bold\", labelpad=5)\n",
    "plt.ylabel('Density', fontsize=18, \n",
    "           fontname='Arial', fontweight=\"bold\", labelpad=5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Single_target.jpeg', dpi=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
