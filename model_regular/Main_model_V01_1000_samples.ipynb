{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "564dafda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from matplotlib import rc, rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.lines as mlines\n",
    "from   matplotlib.lines import Line2D\n",
    "from   matplotlib.colors import ListedColormap\n",
    "import matplotlib.ticker as tk\n",
    "\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "import multiprocessing\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import (Input, Dropout, LSTM, Reshape, LeakyReLU,\n",
    "                          Concatenate, ReLU, Flatten, Dense, Embedding,\n",
    "                          BatchNormalization, Activation, SpatialDropout1D,\n",
    "                          Conv2D, MaxPooling2D, UpSampling2D, Lambda)\n",
    "from tensorflow.keras.models     import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses     import mse, binary_crossentropy\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.metrics import  mean_squared_error as mse_keras\n",
    "from tensorflow.keras.backend import argmax as argmax\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow import one_hot\n",
    "from tensorflow.keras.models import Sequential \n",
    "\n",
    "from tensorflow.keras.utils import  to_categorical\n",
    "from tensorflow import random as randomtf\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "from progressbar import ProgressBar\n",
    "import seaborn as sns\n",
    "\n",
    "from chainer_chemistry.dataset.preprocessors import GGNNPreprocessor, construct_atomic_number_array\n",
    "preprocessor = GGNNPreprocessor()\n",
    "from rdkit import rdBase\n",
    "rdBase.DisableLog('rdApp.error')\n",
    "from rdkit import Chem\n",
    "\n",
    "import ntpath\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "# import general file from utils as shared packages\n",
    "import sys\n",
    "sys.path.append(\"./../utils/\")\n",
    "from general import *\n",
    "\n",
    "randomtf.set_seed(10)\n",
    "os.environ['PYTHONHASHSEED'] = '10'\n",
    "np.random.seed(420)\n",
    "random.seed(123450)\n",
    "from progressbar import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "daa193c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 00:12:24.345406: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-14 00:12:24.345571: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-14 00:12:24.345648: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-14 00:12:24.345747: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-14 00:12:24.345806: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-14 00:12:24.345850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16970 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# GPU memory control\n",
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.7)\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, \n",
    "                                        inter_op_parallelism_threads=1, gpu_options=gpu_options)\n",
    "tf.compat.v1.set_random_seed(1234)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "tf.compat.v1.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0597c93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '!!!Ariaaaal')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check the font !!!!!!!!!!!!!!!!!!!!!\n",
    "# switch to Arial\n",
    "# if not working in Linux delet ~/.catch/matplotlib\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.rcParams['ps.useafm'] = True\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "mpl.font_manager.FontManager()\n",
    "\n",
    "rc('font', weight='bold')\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "plt.scatter([10, 55], [10, 55])\n",
    "ax.tick_params(axis='both', length=0, width=1.5, colors='black', grid_alpha=0, labelsize=20)\n",
    "plt.xlabel('!!!Ariaaaal', fontname='Arial', fontsize=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f38a886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106101, 40, 27, 1)\n",
      "(24819, 40, 27, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" reading and preprocessing data\"\"\"\n",
    "with open('./../data/trainingsets/train_regular_pubqc130K/image_train.pickle', 'rb') as f:\n",
    "    X_smiles_train0, SMILES_train0, y_train00 = pickle.load(f)\n",
    "    \n",
    "with open('./../data/trainingsets/train_regular_pubqc130K/image_test.pickle', 'rb') as f:\n",
    "    X_smiles_val0, SMILES_val0, y_val00 = pickle.load(f)\n",
    "\n",
    "with open('./../data/trainingsets/train_regular_pubqc130K/tokenizer.pickle', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "tokenizer[0] = ' '\n",
    "\n",
    "with open('./../data/trainingsets/train_regular_pubqc130K/tokenizer_object.pickle', 'rb') as f:\n",
    "    tokenizer_ = pickle.load(f)\n",
    "    \n",
    "print (X_smiles_train0.shape)\n",
    "print (X_smiles_val0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35da8a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106101, 40, 27, 1)\n",
      "(24819, 40, 27, 1)\n"
     ]
    }
   ],
   "source": [
    "# In case of reduceing the number of samples\n",
    "idx = np.random.choice(len(y_train00), int(len(y_train00) * 1), replace = False)\n",
    "X_smiles_train, SMILES_train, y_train0 = (X_smiles_train0[idx], SMILES_train0[idx], y_train00[idx])\n",
    "idx = np.random.choice(len(y_val00), int(len(y_val00) * 1), replace = False)\n",
    "X_smiles_val, SMILES_val, y_val0 = (X_smiles_val0[idx], SMILES_val0[idx], y_val00[idx])\n",
    "\n",
    "print (X_smiles_train.shape)\n",
    "print (X_smiles_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae5cffd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.048\n",
      "10.985\n",
      "1.148\n",
      "10.757\n"
     ]
    }
   ],
   "source": [
    "print (min(y_train00))\n",
    "print (max(y_train00))\n",
    "print (min(y_val0))\n",
    "print (max(y_val0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5288e91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9779090909090908\n",
      "0.9986363636363635\n"
     ]
    }
   ],
   "source": [
    "# Standardized between 0 and 11\n",
    "gap_min = 0\n",
    "gap_max = 11\n",
    "\n",
    "y_val = NormalizeData(y_val0, min_data=gap_min, max_data=gap_max)\n",
    "y_train = NormalizeData(y_train0, min_data=gap_min, max_data=gap_max)\n",
    "\n",
    "print (max(y_val))\n",
    "print (max(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55edf674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 00:12:25.152379: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-14 00:12:25.152551: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-14 00:12:25.152609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-14 00:12:25.152815: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-14 00:12:25.152881: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-14 00:12:25.152931: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-14 00:12:25.153018: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-14 00:12:25.153072: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-14 00:12:25.153110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16970 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-08-14 00:12:25.164859: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:735] failed to allocate 16.57G (17794531328 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-08-14 00:12:25.165794: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:735] failed to allocate 14.92G (16015077376 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-08-14 00:12:25.166654: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:735] failed to allocate 13.42G (14413569024 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-08-14 00:12:25.167522: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:735] failed to allocate 12.08G (12972212224 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" models definition and extracting pretrained encoder and decoder \"\"\"\n",
    "# encoder and decoder should be trained using another file named embedding.\n",
    "encoder = load_model('./../data/nns/keep/encoder.h5')\n",
    "decoder = load_model('./../data/nns/keep/decoder.h5')\n",
    "\n",
    "class Config:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.Filters = [256, 128, 64]\n",
    "        self.genFilters = [128, 128, 128]\n",
    "        self.upFilters = [(2, 2), (2, 2), (2, 2)]\n",
    "        \n",
    "config = Config()\n",
    "\n",
    "## Generator \n",
    "z = Input(shape = (128, ))\n",
    "y = Input(shape = (1, ))\n",
    "\n",
    "h = Concatenate(axis = 1)([z, y])\n",
    "h = Dense(1 * 1 * 128)(h)\n",
    "R1 = Reshape([1, 1, 128])(h)\n",
    "R2 = Reshape([1, 1, 128])(h)\n",
    "\n",
    "for i in range(3):\n",
    "    R1 = UpSampling2D(size = config.upFilters[i])(R1)\n",
    "    C1 = Conv2D(filters = config.genFilters[i], \n",
    "               kernel_size = 2, \n",
    "               strides = 1, \n",
    "               padding = 'same')(R1)\n",
    "    B1 = BatchNormalization()(C1)\n",
    "    R1 = LeakyReLU(alpha=0.2)(B1)\n",
    "\n",
    "for i in range(3):\n",
    "    R2 = UpSampling2D(size = config.upFilters[i])(R2)\n",
    "    C2 = Conv2D(filters = config.genFilters[i], \n",
    "               kernel_size = 2, \n",
    "               strides = 1, \n",
    "               padding = 'same')(R2)\n",
    "    B2 = BatchNormalization()(C2)\n",
    "    R2 = LeakyReLU(alpha=0.2)(B2)\n",
    "    \n",
    "R1 = Conv2D(1,\n",
    "            kernel_size = 3,\n",
    "            strides = 1,\n",
    "            padding = 'valid',\n",
    "            activation = 'tanh')(R1)\n",
    "R2 = Conv2D(1,\n",
    "            kernel_size = 3,\n",
    "            strides = 1,\n",
    "            padding = 'valid',\n",
    "            activation = 'tanh')(R2)\n",
    "\n",
    "generator = Model([z, y], [R1, R2])\n",
    "\n",
    "## Discriminator \n",
    "inp1 = Input(shape = [6, 6, 1])\n",
    "inp2 = Input(shape = [6, 6, 1])\n",
    "\n",
    "X1 = Concatenate()([inp1, inp2])\n",
    "X = Flatten()(X1)\n",
    "y2 = Concatenate(axis = 1)([X, y])\n",
    "for i in range(3):\n",
    "\t\ty2 = Dense(64, activation = 'relu')(y2)\n",
    "\t\ty2 = LeakyReLU(alpha = 0.2)(y2)\n",
    "\t\ty2 = Dropout(0.2)(y2)\n",
    "\n",
    "O_dis = Dense(1, activation = 'sigmoid')(y2)\n",
    "\n",
    "\n",
    "discriminator = Model([inp1, inp2, y], O_dis)\n",
    "discriminator.compile(loss = 'binary_crossentropy', optimizer = Adam(lr = 5e-5, beta_1 = 0.5))\n",
    "\n",
    "## Regressor\n",
    "inp1 = Input(shape = [6, 6, 1])\n",
    "inp2 = Input(shape = [6, 6, 1])\n",
    "\n",
    "yr = Concatenate()([inp1, inp2])\n",
    "\n",
    "tower0 = Conv2D(64, 1, padding = 'same')(yr)\n",
    "tower1 = Conv2D(64, 1, padding = 'same')(yr)\n",
    "tower1 = Conv2D(64, 3, padding = 'same')(tower1)\n",
    "tower2 = Conv2D(32, 1, padding = 'same')(yr)\n",
    "tower2 = Conv2D(32, 5, padding = 'same')(tower2)\n",
    "tower3 = MaxPooling2D(3, 1, padding = 'same')(yr)\n",
    "tower3 = Conv2D(32, 1, padding = 'same')(tower3)\n",
    "h = Concatenate()([tower0, tower1, tower2, tower3])\n",
    "h = ReLU()(h)\n",
    "h = MaxPooling2D(2, 1, padding = 'same')(h)\n",
    "\n",
    "for i in range(6):\n",
    "    tower0 = Conv2D(64, 1, padding = 'same')(h)\n",
    "    tower1 = Conv2D(64, 1, padding = 'same')(h)\n",
    "    tower1 = Conv2D(64, 3, padding = 'same')(tower1)\n",
    "    tower2 = Conv2D(32, 1, padding = 'same')(h)\n",
    "    tower2 = Conv2D(32, 5, padding = 'same')(tower2)\n",
    "    tower3 = MaxPooling2D(3, 1, padding = 'same')(h)\n",
    "    tower3 = Conv2D(32, 1, padding = 'same')(tower3)\n",
    "    h = Concatenate()([tower0, tower1, tower2, tower3])\n",
    "    h = ReLU()(h)\n",
    "    if i % 2 == 0 and i != 0:\n",
    "        h = MaxPooling2D(2, 1, padding = 'same')(h)\n",
    "h = BatchNormalization()(h)\n",
    "\n",
    "yr = Flatten()(h)\n",
    "o = Dropout(0.2)(yr)\n",
    "o = Dense(128)(o)\n",
    "\n",
    "o_reg = Dropout(0.2)(o)\n",
    "o_reg = Dense(1, activation = 'sigmoid')(o_reg)\n",
    "\n",
    "regressor = Model([inp1, inp2], o_reg)\n",
    "regressor_top = Model([inp1, inp2], o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b74e336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Regressor \n",
    "# pretrained encoder and decoder \n",
    "train_atoms_embedding, train_bonds_embedding, _ = encoder.predict([X_smiles_train], verbose=0)\n",
    "atoms_embedding, bonds_embedding, _ = encoder.predict([X_smiles_train], verbose=0)\n",
    "atoms_val, bonds_val, _ = encoder.predict([X_smiles_val], verbose=0)\n",
    "\n",
    "regressor.trainable=True\n",
    "regressor_top.trainable=True\n",
    "try:\n",
    "    regressor = load_model('./../data/nns/keep/regressor.h5')\n",
    "    regressor_top = load_model('./../data/nns/keep/regressor_top.h5')\n",
    "    regressor.compile(loss = 'mse', optimizer = Adam(5e-7))\n",
    "    print (\".h5 was read\")\n",
    "except:\n",
    "    print (\"no .h5 available\")\n",
    "    regressor.compile(loss = 'mse', optimizer = Adam(1e-6))\n",
    "    pass\n",
    "    \n",
    "history = regressor.fit([atoms_embedding, bonds_embedding], \n",
    "              y_train,\n",
    "              validation_data = ([atoms_val,\n",
    "                                  bonds_val],\n",
    "                                 y_val),\n",
    "              batch_size = 512,\n",
    "              epochs = 1,\n",
    "              verbose = 1)\n",
    "    \n",
    "# Validating the regressor\n",
    "# Train\n",
    "pred_train = regressor.predict([atoms_embedding, bonds_embedding])\n",
    "pred_train0 = pred_train*(gap_max-gap_min)+gap_min\n",
    "print('Current R2 on Regressor for train data: {}'.format(\n",
    "    r2_score(y_train0, pred_train0.reshape([-1]))))\n",
    "mse_train = mean_squared_error(y_train0, pred_train0.reshape([-1]))\n",
    "mae_train = mean_absolute_error(y_train0, pred_train0.reshape([-1]))\n",
    "\n",
    "# Test\n",
    "pred = regressor.predict([atoms_val, bonds_val])\n",
    "pred0 = pred*(gap_max-gap_min) + gap_min\n",
    "print('Current R2 on Regressor for test data: {}'.format(r2_score(y_val0, pred0.reshape([-1]))))\n",
    "mse_test = mean_squared_error (y_val0, pred0.reshape([-1]))\n",
    "mae_test = mean_absolute_error (y_val0, pred0.reshape([-1]))\n",
    "\n",
    "print ('Train MSE: {}, RMSE: {}, MAE: {}'.format (round(mse_train, 5), \n",
    "                                                  round(mse_train**0.5, 5), \n",
    "                                                  round(mae_train, 5)))\n",
    "print ('Test MSE: {}, RMSE: {}, MAE: {}'.format (round(mse_test, 5), \n",
    "                                                  round(mse_test**0.5, 5), \n",
    "                                                  round(mae_test, 5)))\n",
    "# Saving the currently trained models\n",
    "regressor.save('./../data/nns/regressor.h5')\n",
    "regressor_top.save('./../data/nns/regressor_top.h5')\n",
    "\n",
    "# min. and max. of prediction\n",
    "print (np.max(pred0))\n",
    "print (np.max(y_train0))\n",
    "print (np.max(pred_train0))\n",
    "print (np.max(y_val0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9165cbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_pred_des = np.round (mean_absolute_error(pred0, y_val0), 4)\n",
    "print (\"MAE_pred_des\", MAE_pred_des)\n",
    "# Fractioned MAE, more normalized\n",
    "Fractioned_MAE_pred_des = 0\n",
    "for pred, true in zip(pred0, y_val0):\n",
    "        Fractioned_MAE_pred_des = Fractioned_MAE_pred_des +  abs(pred-true)/true\n",
    "Fractioned_MAE_pred_des = Fractioned_MAE_pred_des/(pred0.shape[0])\n",
    "print (\"MAEF_pred_des\", Fractioned_MAE_pred_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360345c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "plt.rcParams[\"legend.markerscale\"] = 10\n",
    "plt.scatter (y_train0, pred_train0, color='red', label='Train', alpha=0.6, s=0.05)\n",
    "plt.scatter ( y_val0, pred0, color='blue', label='Test', alpha=0.6, s=0.05)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "ax.set_xlabel('DFT gap (eV)', fontsize='20', fontname='Arial', fontweight='bold', labelpad=5)\n",
    "ax.set_ylabel('Pred. gap (eV)', fontsize='20', fontname='Arial', fontweight='bold', labelpad=5)\n",
    "\n",
    "ax.tick_params(direction='out', length=5, width=3, colors='black', \n",
    "               grid_alpha=1, labelsize='18')\n",
    "\n",
    "[i.set_linewidth(3) for i in ax.spines.values()]\n",
    "leg = plt.legend(title='Train: R$^2$={}, MAE={} \\nTest: R$^2$={}, MAE={}'.\\\n",
    "           format(round(r2_score(y_train0, pred_train0.reshape([-1])), 2), \n",
    "                  round (mae_train, 2),\n",
    "                  round (r2_score(y_val0, pred0.reshape([-1])), 2), \n",
    "                  round (mae_test, 2), ), framealpha=0, title_fontsize=15)\n",
    "leg._legend_box.align = \"left\"\n",
    "\n",
    "plt.xlim(0, 12)\n",
    "plt.ylim(0, 12)\n",
    "plt.xticks((1, 3, 5, 7, 9,  11));\n",
    "plt.yticks((1, 3, 5, 7, 9,  11));\n",
    "plt.plot([0, 12], [0, 12], '--k', )#color='black')\n",
    "plt.tight_layout()\n",
    "plt.savefig('regressor_train_test.jpeg', dpi=300)\n",
    "plt.rcParams[\"legend.markerscale\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d457c870",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combined model, train the Generator inside this combined model\n",
    "def build_combined(z, y,\n",
    "                   regressor,\n",
    "                   regressor_top,\n",
    "                   discriminator,\n",
    "                   encoder,\n",
    "                   decoder):\n",
    "    discriminator.trainable = False\n",
    "    regressor_top.trainable = False\n",
    "    regressor.trainable = False\n",
    "    encoder.trainable = False\n",
    "    decoder.trainable = False\n",
    "    \n",
    "    atoms_emb, bonds_emb = generator([z, y])\n",
    "    dec_embedding = Concatenate()([atoms_emb, bonds_emb])\n",
    "    \n",
    "    softmax_smiles, _ = decoder([dec_embedding])\n",
    "    argmax_smiles = argmax (softmax_smiles, axis=2)\n",
    "    argmax_smiles = Reshape([40])(argmax_smiles)\n",
    "    smiles = one_hot(argmax_smiles, depth=27)\n",
    "    smiles = Reshape([40, 27, 1])(smiles)\n",
    "    latent_encoder_atom, latent_encoder_bond, _ = encoder ([smiles])\n",
    "    \n",
    "    y_pred = regressor([latent_encoder_atom, latent_encoder_bond])\n",
    "    valid = discriminator([atoms_emb, bonds_emb, y])\n",
    "    #print ('valid from comb', valid)\n",
    "\n",
    "    combined = Model([z, y], [valid, y_pred])\n",
    "\n",
    "    combined.compile(loss = ['binary_crossentropy',\n",
    "                             'mse'], \n",
    "                     loss_weights = [0.01, 25.0], \n",
    "                     optimizer = Adam(5e-6, beta_1 = 0.5))\n",
    "    \n",
    "    return combined\n",
    "\n",
    "combined = build_combined(z, y,\n",
    "                          regressor,\n",
    "                          regressor_top,\n",
    "                          discriminator,\n",
    "                          encoder,\n",
    "                          decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c2af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = multiprocessing.Process()\n",
    "\"\"\" Training RCGAN \"\"\"\n",
    "# loading pretrained models\n",
    "regressor = load_model    ('./../data/nns/regressor.h5')\n",
    "regressor_top = load_model('./../data/nns/regressor_top.h5')\n",
    "#generator = load_model    ('./../data/nns/keep/generator.h5')\n",
    "#discriminator = load_model ('./../data/nns/keep/discriminator.h5')\n",
    "\n",
    "regressor_top.trainable = False\n",
    "regressor.trainable = False\n",
    "\n",
    "# SMILES related information\n",
    "max_gen_atoms = 9\n",
    "bond_max = 9\n",
    "MAX_NB_WORDS = 27\n",
    "MAX_SEQUENCE_LENGTH = 40\n",
    "\n",
    "\n",
    "epochs = 1000\n",
    "batch_size = 128\n",
    "batches = y_train0.shape[0] // batch_size\n",
    "threshold = 0.2 # defining accurate samples\n",
    "reinforce_n = 50 # 5*reinforce_n = fake sampling\n",
    "reinforce_sample = 1000 # how many samples generated for Reinforcement\n",
    "\n",
    "# variable for storing generated data\n",
    "G_Losses = []\n",
    "D_Losses = []\n",
    "R_Losses = []\n",
    "D_Losses_real = []\n",
    "D_Losses_fake = []\n",
    "\n",
    "for e in range(epochs):\n",
    "    start = time.time()\n",
    "    D_loss = []\n",
    "    G_loss = []\n",
    "    R_loss = []\n",
    "    D_loss_real = []\n",
    "    D_loss_fake = []\n",
    "    \n",
    "    for b in range(batches):\n",
    "        \n",
    "        regressor_top.trainable = False\n",
    "        regressor.trainable = False\n",
    "\n",
    "        idx = np.arange(b * batch_size, (b + 1) * batch_size)\n",
    "        # rearrange the samples \n",
    "        idx = np.random.choice(idx, batch_size, replace = False)\n",
    "        \n",
    "        x_smiles_train = X_smiles_train[idx] \n",
    "        batch_y = y_train[idx]\n",
    "        \n",
    "        batch_z = np.random.normal(0, 1, size = (batch_size, 128))\n",
    "        \n",
    "        atoms_embedding, bonds_embedding, _ = encoder.predict([x_smiles_train], verbose=0)\n",
    "        dec_embedding = np.concatenate([atoms_embedding, bonds_embedding], axis = -1)\n",
    "        \n",
    "        gen_atoms_embedding, gen_bonds_embedding = generator.predict([batch_z, batch_y], verbose=0)\n",
    "        gen_dec_embedding = np.concatenate([gen_atoms_embedding, gen_bonds_embedding], axis = -1)\n",
    "\n",
    "        softmax_smiles = decoder.predict(gen_dec_embedding, verbose=0)[0]\n",
    "        argmax_smiles = np.argmax(softmax_smiles, axis = 2)\n",
    "        smiles = to_categorical(argmax_smiles, num_classes=27)\n",
    "        SHAPE = list(smiles.shape) + [1]\n",
    "        smiles = smiles.reshape(SHAPE)\n",
    "        latent_encoder_atom, latent_encoder_bond, _ = encoder.predict([smiles], verbose=0)\n",
    "        gen_pred = regressor.predict([latent_encoder_atom, latent_encoder_bond], verbose=0).reshape([-1])\n",
    "        \n",
    "        regressor.trainable = True\n",
    "        r_loss = regressor.train_on_batch([atoms_embedding, bonds_embedding], batch_y)\n",
    "        R_loss.append(r_loss)\n",
    "        regressor.trainable = False\n",
    "\n",
    "        discriminator.trainable = True\n",
    "        d = 3 # hyperparamter\n",
    "        for _ in range(d):\n",
    "            d_loss_real = discriminator.train_on_batch([atoms_embedding, bonds_embedding, batch_y],\n",
    "                                                       [0.9 * np.ones((batch_size, 1))])\n",
    "            d_loss_fake = discriminator.train_on_batch([gen_atoms_embedding, gen_bonds_embedding, batch_y],\n",
    "                                                       [np.zeros((batch_size, 1))]) \n",
    "\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        D_loss.append(d_loss)\n",
    "        D_loss_real.append (d_loss_real)\n",
    "        D_loss_fake.append (d_loss_fake)\n",
    "        discriminator.trainable = False\n",
    "        \n",
    "        regressor_top.trainable = False\n",
    "        regressor.trainable = False\n",
    "\n",
    "        g_loss = combined.train_on_batch([batch_z, batch_y], [0.9 * np.ones((batch_size, 1)), batch_y])\n",
    "        G_loss.append(g_loss[0])\n",
    "    \n",
    "    D_Losses.append(np.mean(D_loss))\n",
    "    D_Losses_real.append(np.mean(D_loss_real))\n",
    "    D_Losses_fake.append(np.mean(D_loss_fake))\n",
    "    G_Losses.append(np.mean(G_loss))\n",
    "    R_Losses.append(np.mean(R_loss))\n",
    "    \n",
    "    print('====')\n",
    "    print('Current epoch: {}/{}'.format((e + 1), epochs))\n",
    "    print ('D Loss Real: {}'.format(np.mean(D_loss_real)))\n",
    "    print ('D Loss Fake: {}'.format(np.mean(D_loss_fake)))\n",
    "    print('D Loss: {}'.format(np.mean(D_loss)))\n",
    "    print('G Loss: {}'.format(np.mean(G_loss)))\n",
    "    print('R Loss: {}'.format(np.mean(R_loss)))\n",
    "    print('====')\n",
    "    print()\n",
    "\n",
    "    \n",
    "    # Reinforcement\n",
    "    gen_error = []\n",
    "    gen_smiles = []\n",
    "    gen_valid_smiles = []\n",
    "    gen_X_atoms = []\n",
    "    gen_X_bonds = []\n",
    "    predcv_AE_latent = []\n",
    "    embeddings = []\n",
    "    sample_ys = []\n",
    "    valid_smiles_index = []\n",
    "    for _ in range(reinforce_sample):\n",
    "        sample_y = np.random.uniform(gap_min, gap_max, size = [1, ])\n",
    "        sample_y = np.round(sample_y, 4)\n",
    "        sample_y = (sample_y - gap_min) / (gap_max - gap_min)\n",
    "        sample_ys.append(sample_y)\n",
    "\n",
    "        sample_z = np.random.normal(0, 1, size = (1, 128))\n",
    "\n",
    "        sample_atoms_embedding, sample_bonds_embedding = generator.predict([sample_z, sample_y], verbose=0)\n",
    "        embeddings.append((sample_atoms_embedding, sample_bonds_embedding))\n",
    "        \n",
    "        dec_embedding = np.concatenate([sample_atoms_embedding, sample_bonds_embedding], axis = -1)\n",
    "        softmax_smiles = decoder.predict(dec_embedding, verbose=0)[0]\n",
    "        argmax_smiles = np.argmax(softmax_smiles, axis = 2).reshape([-1])\n",
    "        smiles = to_categorical(argmax_smiles, num_classes=27)\n",
    "        SHAPE = [1] + list(smiles.shape) + [1]\n",
    "        smiles = smiles.reshape(SHAPE)\n",
    "        c_smiles = ''\n",
    "        for s in argmax_smiles:\n",
    "            c_smiles += tokenizer[s]\n",
    "        c_smiles = c_smiles.rstrip()\n",
    "        \n",
    "        gen_smiles.append(c_smiles)\n",
    "        latent_encoder_atom, latent_encoder_bond, _ = encoder.predict([smiles], verbose=0)\n",
    "        reg_pred = regressor.predict([latent_encoder_atom, latent_encoder_bond], verbose=0)\n",
    "        \n",
    "        pred, desire = reg_pred[0][0], sample_y[0]\n",
    "        gen_error.append(round (np.abs((pred - desire) / desire), 5))\n",
    "\n",
    "        \n",
    "    gen_error = np.asarray(gen_error)\n",
    "    # two validity defined: \n",
    "    ## without sanitizing: valid0 , sanitized=valid\n",
    "    valid = 0\n",
    "    valid0 = 0\n",
    "    idx_ = []\n",
    "    idx0_ = []\n",
    "    for iter_, smiles in enumerate(gen_smiles):\n",
    "        if ' ' in smiles[:-1]:\n",
    "            continue\n",
    "        m  = Chem.MolFromSmiles(smiles[:-1], sanitize=True)\n",
    "        m0 = Chem.MolFromSmiles(smiles[:-1], sanitize=False)\n",
    "        if m0 is not None:\n",
    "            valid0 += 1\n",
    "            idx0_.append(iter_)\n",
    "        if m is not None:\n",
    "            valid += 1\n",
    "            idx_.append(iter_)\n",
    "            try:\n",
    "                gen_smiles [iter_] = Chem.MolToSmiles(m, canonical=True)\n",
    "                print (Chem.MolToSmiles(m, canonical=True))\n",
    "                print (\"gap_des\", sample_ys[iter_])\n",
    "                print (\"error\", gen_error[iter_])\n",
    "            except:\n",
    "                pass\n",
    "    idx_ = np.asarray(idx_)\n",
    "    idx0_ = np.asarray(idx0_)\n",
    "\n",
    "    validity = [gen_smiles[jj] for jj in idx0_ ]\n",
    "    validity = pd.DataFrame(validity)\n",
    "    validity = validity.drop_duplicates()\n",
    "\n",
    "    validity_sanitize = [gen_smiles[jj] for jj in idx_ ]\n",
    "    validity_sanitize = pd.DataFrame(validity_sanitize)\n",
    "    validity_sanitize = validity_sanitize.drop_duplicates()\n",
    "\n",
    "    if (e + 1) % 100 == 0:\n",
    "        reinforce_n += 10\n",
    "\n",
    "    # invalid smiles:\n",
    "    fake_indices1 = np.setdiff1d(np.arange(reinforce_sample), np.asarray(idx_))\n",
    "    fake_indices2 = np.intersect1d(np.where(gen_error > threshold)[0], idx_)\n",
    "    fake_indices = np.concatenate ((fake_indices1, fake_indices2))\n",
    "    fake_indices = np.random.choice(fake_indices, reinforce_n * 5, replace = False)\n",
    "\n",
    "    real_indices_ = np.intersect1d(np.where(gen_error <= threshold)[0], idx_)\n",
    "    sample_size =  len(real_indices_)\n",
    "    real_indices = np.random.choice(real_indices_, sample_size, replace = False)\n",
    "    \n",
    "    # Activating Reinforcement \n",
    "    # hyperparamter, how many initial training of GAN\n",
    "    if e >= 5:\n",
    "        discriminator.trainable = True\n",
    "        regressor_top.trainable = False\n",
    "        regressor.trainable = False\n",
    "        for real_index in real_indices:\n",
    "            _ = discriminator.train_on_batch([embeddings[real_index][0], \n",
    "                                              embeddings[real_index][1], \n",
    "                                              sample_ys[real_index]],\n",
    "                                             [1 * np.ones((1, 1))])\n",
    "\n",
    "        for fake_index in fake_indices:\n",
    "            _ = discriminator.train_on_batch([embeddings[fake_index][0], \n",
    "                                              embeddings[fake_index][1] , \n",
    "                                              sample_ys[fake_index]],\n",
    "                                             [np.zeros((1, 1))])\n",
    "        discriminator.trainable = False\n",
    "\n",
    "    # ==== #\n",
    "    try:\n",
    "        print('Currently valid SMILES (No chemical_beauty and sanitize off): {}'.format(valid0))\n",
    "        print('Currently valid SMILES Unique (No chemical_beauty and sanitize off): {}'.format(len(validity)))\n",
    "        print('Currently valid SMILES Sanitized: {}'.format(valid))\n",
    "        print('Currently valid Unique SMILES Sanitized: {}'.format(len(validity_sanitize)))\n",
    "        print('Currently satisfying SMILES: {}'.format(len(real_indices_)))\n",
    "        print('Currently unique satisfying generation: {}'.format(len(np.unique(np.array(gen_smiles)[real_indices_]))))\n",
    "        print('====')\n",
    "        print()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if (e + 1) % 5 == 0:\n",
    "        plt.close()\n",
    "        fig, ax = plt.subplots(figsize = (12, 10))\n",
    "        ax.tick_params(axis='both', which='major', labelsize=30)\n",
    "        plt.plot(G_Losses, color='blue')\n",
    "        plt.plot(D_Losses, color='red')\n",
    "        plt.xlabel('epochs', fontsize=35)\n",
    "        plt.ylabel('loss', fontsize=35)\n",
    "        mpl.rcParams['axes.linewidth'] = 2.5\n",
    "        plt.legend(['G Loss', 'D Loss'], fontsize=30)\n",
    "        plt.savefig(\"G_D_losses{}.png\".format (e+1))\n",
    "    \n",
    "\n",
    "    n_unique = len(np.unique(np.array(gen_smiles)[real_indices_]))\n",
    "    n_valid = valid\n",
    "\n",
    "    end = time.time()\n",
    "    print (\"time for current epoch: \", (end - start))\n",
    "\n",
    "    tf.compat.v1.keras.backend.clear_session()\n",
    "with open('GAN_loss.pickle', 'wb') as f:\n",
    "    pickle.dump((G_Losses, D_Losses, R_Losses), f)\n",
    "\n",
    "# Saving the currently trained models\n",
    "generator.save('./../data/nns/generator.h5')\n",
    "discriminator.save('./../data/nns/discriminator.h5')\n",
    "combined.save('./../data/nns/combined.h5')\n",
    "\n",
    "p.start()\n",
    "p.join()\n",
    "tf.compat.v1.keras.backend.clear_session()\n",
    "print ('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7e15d4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 851 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd3a00e7550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 851 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd3a00e7550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed 31\n",
      "explained_varice_R2_pred_des 0.75623554122657\n",
      "r squared r**2 0.7396\n",
      "MAE_pred_des 1.1466\n",
      "% < 20 RE 0.7121\n",
      "RE mean 0.2516\n",
      "best r2 0.7396\n",
      "best random seed 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed 38\n",
      "explained_varice_R2_pred_des 0.6791818937148661\n",
      "r squared r**2 0.6643\n",
      "MAE_pred_des 1.1808\n",
      "% < 20 RE 0.7536\n",
      "RE mean 0.2288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed 50\n",
      "explained_varice_R2_pred_des 0.6887605958275116\n",
      "r squared r**2 0.6606\n",
      "MAE_pred_des 1.1712\n",
      "% < 20 RE 0.7333\n",
      "RE mean 0.2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed 86\n",
      "explained_varice_R2_pred_des 0.6201032125965327\n",
      "r squared r**2 0.6156\n",
      "MAE_pred_des 1.0894\n",
      "% < 20 RE 0.7794\n",
      "RE mean 0.2826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed 78\n",
      "explained_varice_R2_pred_des 0.6942430996874939\n",
      "r squared r**2 0.6786\n",
      "MAE_pred_des 1.1298\n",
      "% < 20 RE 0.6842\n",
      "RE mean 0.1945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed 84\n",
      "explained_varice_R2_pred_des 0.713422534478913\n",
      "r squared r**2 0.7115\n",
      "MAE_pred_des 1.3377\n",
      "% < 20 RE 0.6452\n",
      "RE mean 0.3537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed 89\n",
      "explained_varice_R2_pred_des 0.698434534144166\n",
      "r squared r**2 0.6856\n",
      "MAE_pred_des 1.3304\n",
      "% < 20 RE 0.6552\n",
      "RE mean 0.3084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed 92\n",
      "explained_varice_R2_pred_des 0.6155526793910358\n",
      "r squared r**2 0.6142\n",
      "MAE_pred_des 1.1637\n",
      "% < 20 RE 0.72\n",
      "RE mean 0.2397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed 48\n",
      "explained_varice_R2_pred_des 0.7033864417014137\n",
      "r squared r**2 0.7021\n",
      "MAE_pred_des 1.1115\n",
      "% < 20 RE 0.6207\n",
      "RE mean 0.3133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed 51\n",
      "explained_varice_R2_pred_des 0.6165736924726635\n",
      "r squared r**2 0.6143\n",
      "MAE_pred_des 1.0905\n",
      "% < 20 RE 0.7077\n",
      "RE mean 0.2044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = load_model('./../data/nns/keep/encoder.h5')\n",
    "decoder = load_model('./../data/nns/keep/decoder.h5')\n",
    "model = load_model('./../data/nns/keep/ae_model.h5')\n",
    "\n",
    "regressor = load_model    ('./../data/nns/keep/regressor.h5')\n",
    "regressor_top = load_model('./../data/nns/keep/regressor_top.h5')\n",
    "generator = load_model    ('./../data/nns/keep/generator.h5')\n",
    "discriminator= load_model ('./../data/nns/keep/discriminator.h5')\n",
    "\n",
    "pbar = ProgressBar()\n",
    "max = 0.3\n",
    "\n",
    "randS = []\n",
    "rsquaredS = []\n",
    "MAE_S = []\n",
    "less20RE_perS = []\n",
    "output_lenS = []\n",
    "mean_RE_S = []\n",
    "randoms = [31, 38, 50, 86, 78, 84, 89, 92, 48, 51]\n",
    "for rand in pbar( (randoms)):  \n",
    "    N = 50\n",
    "    n_sample = 70\n",
    "    gen_error = []\n",
    "    gen_smiles = []\n",
    "    sample_ys = []\n",
    "    preds = []\n",
    "  \n",
    "    predss_can = []\n",
    "    gen_atoms_embedding = []\n",
    "    gen_bonds_embedding = []\n",
    "\n",
    "    regressor_top.trainable = False\n",
    "    regressor.trainable = False\n",
    "    generator.trainable = False\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    np.random.seed(rand)\n",
    "\n",
    "    pbar = ProgressBar()\n",
    "    samples = np.random.uniform(0, 10.7, size=[N, ])\n",
    "    for hc in (pbar(samples)):\n",
    "        try:\n",
    "            # get it back to original of s_min to s_max\n",
    "            #sample_y = np.random.uniform(0, 10.7, size=[1,])\n",
    "            sample_y = hc\n",
    "            #print (sample_y)\n",
    "            sample_y = np.round(sample_y, 4)\n",
    "            sample_y = sample_y * np.ones([N, ])\n",
    "            sample_y_ = (sample_y - gap_min) / (gap_max - gap_min)\n",
    "            sample_z = np.random.normal(0, 1., size = (N, 128))\n",
    "\n",
    "            regressor_top.trainable = False\n",
    "            regressor.trainable = False\n",
    "            encoder.trainable = False\n",
    "            decoder.trainable = False\n",
    "\n",
    "            sample_atoms_embedding, sample_bonds_embedding = generator.predict([sample_z, sample_y_], verbose=0)\n",
    "            dec_embedding = np.concatenate([sample_atoms_embedding, sample_bonds_embedding], axis = -1)\n",
    "\n",
    "            softmax_smiles = decoder.predict(dec_embedding, verbose=0)[0]\n",
    "            argmax_smiles = np.argmax(softmax_smiles, axis = 2)\n",
    "            #print (argmax_smiles)\n",
    "\n",
    "            #print ('shape argmax_smiles', argmax_smiles.shape)\n",
    "            smiles = to_categorical(argmax_smiles, num_classes=27)\n",
    "            \n",
    "            SHAPE = list(smiles.shape) + [1] \n",
    "            \n",
    "            #print ('shape line 767', SHAPE) \n",
    "            smiles = smiles.reshape(SHAPE)\n",
    "\n",
    "            latent_encoder_atom, latent_encoder_bond, _ = encoder.predict([smiles], verbose=0)\n",
    "            pred = regressor.predict([latent_encoder_atom, latent_encoder_bond], verbose=0).reshape([-1])\n",
    "            pred = pred * (gap_max - gap_min) + gap_min\n",
    "\n",
    "            gen_errors = np.abs((pred - sample_y) / sample_y).reshape([-1])\n",
    "\n",
    "\n",
    "            smiles = decoder.predict(dec_embedding, verbose=0)[0]\n",
    "            #print(smiles)\n",
    "            smiles = np.argmax(smiles, axis = 2).reshape(smiles.shape[0], 40)\n",
    "            \n",
    "\n",
    "            generated_smiles = []\n",
    "            \n",
    "            for S in smiles:\n",
    "                c_smiles = ''\n",
    "                for s in S:\n",
    "                    c_smiles += tokenizer[s]\n",
    "                c_smiles = c_smiles.rstrip()\n",
    "                #print (c_smiles)\n",
    "                generated_smiles.append(c_smiles)\n",
    "            generated_smiles = np.array(generated_smiles)\n",
    "            #generated_smiles = generated_smiles [accurate]\n",
    "            all_gen_smiles = []\n",
    "            idx = []\n",
    "            preds_can = []\n",
    "            for i, smiles in enumerate(generated_smiles):\n",
    "                all_gen_smiles.append(smiles[:-1])\n",
    "\n",
    "                if ' ' in smiles[:-1]:\n",
    "                    continue\n",
    "                #m = Chem.MolFromSmiles(smiles[:-1], sanitize=False)\n",
    "                m = Chem.MolFromSmiles(smiles[:-1], sanitize=True)\n",
    "                if m is not None:\n",
    "                    idx.append(i)\n",
    "                    smiles_can = Chem.MolToSmiles(m, canonical=True)\n",
    "                    smiles_can_dot = smiles_can + '.'\n",
    "                    X_smiles0 = tokenizer_.texts_to_sequences([smiles_can_dot])\n",
    "                    X_smiles1 = pad_sequences(X_smiles0, maxlen = 40, padding = 'post')\n",
    "                    X_smiles2 = to_categorical(X_smiles1, num_classes=27)\n",
    "                    latent_encoder_atom, latent_encoder_bond, _ = encoder.predict(X_smiles2, verbose=0)\n",
    "                    pred_can = regressor.predict([latent_encoder_atom, latent_encoder_bond], verbose=0).reshape([-1])\n",
    "                    pred_can = pred_can*11\n",
    "                    preds_can.append(pred_can[0])\n",
    "\n",
    "\n",
    "            idx = np.array(idx)\n",
    "            all_gen_smiles = np.array(all_gen_smiles)\n",
    "            #print ('all gen smiels shape', all_gen_smiles.shape)\n",
    "            #print ('gen_errors shape', gen_errors.shape)\n",
    "            #print (idx)\n",
    "            gen_smiles.extend(list(all_gen_smiles[idx]))\n",
    "            gen_error.extend(list(gen_errors[idx]))\n",
    "            sample_ys.extend(list(sample_y[idx]))\n",
    "            gen_atoms_embedding.extend(sample_atoms_embedding[idx])\n",
    "            gen_bonds_embedding.extend(sample_bonds_embedding[idx])\n",
    "            preds.extend(list(pred[idx]))\n",
    "            predss_can.extend(list(preds_can))\n",
    "        except:\n",
    "            #print('Did not discover SMILES for HC: {}'.format(sample_y))\n",
    "            pass    \n",
    "\n",
    "\n",
    "    output = {}\n",
    "\n",
    "    for i, s in enumerate (gen_smiles):\n",
    "        ss = Chem.MolToSmiles(Chem.MolFromSmiles(s, sanitize=True), canonical=True)\n",
    "        gen_smiles[i] = ss\n",
    "\n",
    "    output['SMILES'] = gen_smiles\n",
    "    output['des_gap'] = sample_ys\n",
    "    # More accurate for regressor to predict gap from canonical SMILES\n",
    "    output['pred_gap'] = predss_can\n",
    "    #output['Err_pred_des'] = gen_error\n",
    "    output['Err_pred_des'] = [abs(i- j)/i for i, j in zip(output['des_gap'], output['pred_gap'])]\n",
    "    output = pd.DataFrame(output)\n",
    "    output.reset_index(drop = True, inplace = True)\n",
    "    output.to_csv ('./../experiments/regular/Initial_training.csv', index=False)\n",
    "\n",
    "    ## Statistics  (# pred=True value, Des=prediction)\n",
    "    # total # of samples\n",
    "    N = len(predss_can)\n",
    "    print ('random seed', rand)\n",
    "\n",
    "    # Explained Variance R2 from sklearn.metrics.explained_variance_score\n",
    "    explained_variance_R2_pred_des = explained_variance_score(output['des_gap'], output['pred_gap'])\n",
    "    print (\"explained_varice_R2_pred_des\", explained_variance_R2_pred_des)\n",
    "    rsquared = np.round (r2_score (output['des_gap'], output['pred_gap']), 4)\n",
    "    print (\"r squared r**2\", rsquared)\n",
    "\n",
    "    # mean absolute error \n",
    "    MAE_pred_des = np.round (mean_absolute_error(output['pred_gap'], output['des_gap']), 4)\n",
    "    print (\"MAE_pred_des\", MAE_pred_des)\n",
    "    # Fractioned MAE, more normalized\n",
    "    Fractioned_MAE_pred_des = 0\n",
    "    for pred, des in zip(output['pred_gap'], output['des_gap']):\n",
    "        Fractioned_MAE_pred_des = Fractioned_MAE_pred_des +  abs(des-pred)/des\n",
    "    Fractioned_MAE_pred_des = Fractioned_MAE_pred_des/N\n",
    "    #print (\"Fractioned MAE_pred_des\", Fractioned_MAE_pred_des)\n",
    "\n",
    "    # root mean squared error (RMSE), sqrt(sklearn ouputs MSE)\n",
    "    RMSE_pred_des = mean_squared_error(output['pred_gap'], output['des_gap'])**0.5\n",
    "    #print (\"RMSE_pred_des\", RMSE_pred_des)\n",
    "\n",
    "    Fractioned_RMSE_pred_des = 0\n",
    "    for pred, des in zip(output['pred_gap'], output['des_gap']):\n",
    "        Fractioned_RMSE_pred_des = Fractioned_RMSE_pred_des + ((des-pred)/des)**2\n",
    "    Fractioned_RMSE_pred_des = (Fractioned_RMSE_pred_des/N)**0.5\n",
    "    #print (\"Fractioned_RMSE_pred_des\", Fractioned_RMSE_pred_des)\n",
    "\n",
    "    # do not drop duplicate\n",
    "    output2 = output.drop_duplicates(['SMILES'])\n",
    "    output2.reset_index(drop = True, inplace = True)\n",
    "    output2.to_csv('./../experiments/regular/Initial_training_nodub.csv', index = False)\n",
    "    \"\"\"with open('gen_pickles.pickle', 'wb') as f:\n",
    "        pickle.dump(gen_unique_pickles, f)\n",
    "    \"\"\"\n",
    "    #print ('% < 20 RE NODUP', sum (output2['Err_pred_des'] < 0.2) / output2['Err_pred_des'].shape[0])\n",
    "    less20RE_per = np.round ((sum(output['Err_pred_des'] <= 0.2) / output['Err_pred_des'].shape[0]), 4)\n",
    "    print ('% < 20 RE', less20RE_per)\n",
    "    output_len = len(output)\n",
    "    explained_variance_R2_pred_des = explained_variance_score(output['des_gap'], output['pred_gap'])\n",
    "    #print (\"explained_varice_R2_pred_des\", explained_variance_R2_pred_des)\n",
    "    mean_RE = np.round (np.mean (output['Err_pred_des']), 4)\n",
    "    print ('RE mean', mean_RE)\n",
    "\n",
    "    randS.append(rand)\n",
    "    rsquaredS.append(rsquared)\n",
    "    MAE_S.append(MAE_pred_des)\n",
    "    less20RE_perS.append(less20RE_per)\n",
    "    mean_RE_S.append(mean_RE)\n",
    "    output_lenS.append(output_len)\n",
    "\n",
    "    if rsquared>max:\n",
    "        good_rand = rand\n",
    "        max = rsquared\n",
    "        best_r2 = rsquared\n",
    "        print ('best r2', best_r2)\n",
    "        print ('best random seed', good_rand)\n",
    "    \n",
    "    tf.compat.v1.keras.backend.clear_session()\n",
    "\n",
    "params = {}\n",
    "params ['rand'] = randS\n",
    "params ['r2'] = rsquaredS\n",
    "params ['MAE'] = MAE_S\n",
    "params ['less20RE_per'] = less20RE_perS\n",
    "params ['Average_RE'] = mean_RE_S\n",
    "params ['total_valid'] = output_lenS\n",
    "params = pd.DataFrame(params)\n",
    "params.reset_index(drop = True, inplace = True)\n",
    "params.to_csv ('./gen_params.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3f368ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed 28\n",
      "explained_varice_R2_pred_des 0.0\n",
      "r squared r**2 0.0\n",
      "MAE_pred_des 0.9362\n",
      "% < 20 RE 0.8529\n",
      "RE mean 0.1129\n",
      "[2441]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "# single target value\n",
    "encoder = load_model('./../data/nns/keep/encoder.h5')\n",
    "decoder = load_model('./../data/nns/keep/decoder.h5')\n",
    "\n",
    "regressor = load_model    ('./../data/nns/keep/regressor.h5')\n",
    "regressor_top = load_model('./../data/nns/keep/regressor_top.h5')\n",
    "generator = load_model    ('./../data/nns/keep/generator.h5')\n",
    "discriminator= load_model ('./../data/nns/keep/discriminator.h5')\n",
    "\n",
    "pbar = ProgressBar()\n",
    "max = 0.3\n",
    "\n",
    "randS = []\n",
    "rsquaredS = []\n",
    "MAE_S = []\n",
    "less20RE_perS = []\n",
    "output_lenS = []\n",
    "mean_RE_S = []\n",
    "for rand in pbar(range (28, 29)):  \n",
    "    N = 50000\n",
    "    n_sample = 1\n",
    "    gen_error = []\n",
    "    gen_smiles = []\n",
    "    sample_ys = []\n",
    "    preds = []\n",
    "  \n",
    "    predss_can = []\n",
    "    gen_atoms_embedding = []\n",
    "    gen_bonds_embedding = []\n",
    "\n",
    "    regressor_top.trainable = False\n",
    "    regressor.trainable = False\n",
    "    generator.trainable = False\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    np.random.seed(rand)\n",
    "\n",
    "    pbar = ProgressBar()\n",
    "    samples = np.random.uniform(1, 11, size=[n_sample, ])\n",
    "    for i, hc in (enumerate(samples)):\n",
    "        try:\n",
    "            # get it back to original of s_min to s_max\n",
    "            #sample_y = np.random.uniform(0, 10.7, size=[1,])\n",
    "            sample_y = hc\n",
    "            #print (sample_y)\n",
    "            sample_y = np.round(sample_y, 4)\n",
    "            sample_y = sample_y * np.ones([N, ])\n",
    "            sample_y_ = (sample_y - gap_min) / (gap_max - gap_min)\n",
    "            sample_z = np.random.normal(0, 1, size = (N, 128))\n",
    "\n",
    "            regressor_top.trainable = False\n",
    "            regressor.trainable = False\n",
    "            encoder.trainable = False\n",
    "            decoder.trainable = False\n",
    "\n",
    "            sample_atoms_embedding, sample_bonds_embedding = generator.predict([sample_z, sample_y_], verbose=0)\n",
    "            dec_embedding = np.concatenate([sample_atoms_embedding, sample_bonds_embedding], axis = -1)\n",
    "\n",
    "            softmax_smiles = decoder.predict(dec_embedding, verbose=0)[0]\n",
    "            argmax_smiles = np.argmax(softmax_smiles, axis = 2)\n",
    "            #print (argmax_smiles)\n",
    "\n",
    "            #print ('shape argmax_smiles', argmax_smiles.shape)\n",
    "            smiles = to_categorical(argmax_smiles, num_classes=27)\n",
    "            \n",
    "            SHAPE = list(smiles.shape) + [1] \n",
    "            \n",
    "            #print ('shape line 767', SHAPE) \n",
    "            smiles = smiles.reshape(SHAPE)\n",
    "\n",
    "            latent_encoder_atom, latent_encoder_bond, _ = encoder.predict([smiles], verbose=0)\n",
    "            pred = regressor.predict([latent_encoder_atom, latent_encoder_bond], verbose=0).reshape([-1])\n",
    "            pred = pred * (gap_max - gap_min) + gap_min\n",
    "\n",
    "            gen_errors = np.abs((pred - sample_y) / sample_y).reshape([-1])\n",
    "\n",
    "\n",
    "            smiles = decoder.predict(dec_embedding, verbose=0)[0]\n",
    "            #print(smiles)\n",
    "            smiles = np.argmax(smiles, axis = 2).reshape(smiles.shape[0], 40)\n",
    "            \n",
    "\n",
    "            generated_smiles = []\n",
    "            \n",
    "            for S in smiles:\n",
    "                c_smiles = ''\n",
    "                for s in S:\n",
    "                    c_smiles += tokenizer[s]\n",
    "                c_smiles = c_smiles.rstrip()\n",
    "                #print (c_smiles)\n",
    "                generated_smiles.append(c_smiles)\n",
    "            generated_smiles = np.array(generated_smiles)\n",
    "            #generated_smiles = generated_smiles [accurate]\n",
    "            all_gen_smiles = []\n",
    "            idx = []\n",
    "            preds_can = []\n",
    "            for i, smiles in enumerate(generated_smiles):\n",
    "                all_gen_smiles.append(smiles[:-1])\n",
    "\n",
    "                if ' ' in smiles[:-1]:\n",
    "                    continue\n",
    "                #m = Chem.MolFromSmiles(smiles[:-1], sanitize=False)\n",
    "                m = Chem.MolFromSmiles(smiles[:-1], sanitize=True)\n",
    "                if m is not None:\n",
    "                    idx.append(i)\n",
    "                    smiles_can = Chem.MolToSmiles(m, canonical=True)\n",
    "                    smiles_can_dot = smiles_can + '.'\n",
    "                    X_smiles0 = tokenizer_.texts_to_sequences([smiles_can_dot])\n",
    "                    X_smiles1 = pad_sequences(X_smiles0, maxlen = 40, padding = 'post')\n",
    "                    X_smiles2 = to_categorical(X_smiles1, num_classes=27)\n",
    "                    latent_encoder_atom, latent_encoder_bond, _ = encoder.predict(X_smiles2, verbose=0)\n",
    "                    pred_can = regressor.predict([latent_encoder_atom, latent_encoder_bond], verbose=0).reshape([-1])\n",
    "                    pred_can = pred_can*11\n",
    "                    preds_can.append(pred_can[0])\n",
    "\n",
    "\n",
    "            idx = np.array(idx)\n",
    "            all_gen_smiles = np.array(all_gen_smiles)\n",
    "            #print ('all gen smiels shape', all_gen_smiles.shape)\n",
    "            #print ('gen_errors shape', gen_errors.shape)\n",
    "            #print (idx)\n",
    "            gen_smiles.extend(list(all_gen_smiles[idx]))\n",
    "            gen_error.extend(list(gen_errors[idx]))\n",
    "            sample_ys.extend(list(sample_y[idx]))\n",
    "            gen_atoms_embedding.extend(sample_atoms_embedding[idx])\n",
    "            gen_bonds_embedding.extend(sample_bonds_embedding[idx])\n",
    "            preds.extend(list(pred[idx]))\n",
    "            predss_can.extend(list(preds_can))\n",
    "        except:\n",
    "            #print('Did not discover SMILES for HC: {}'.format(sample_y))\n",
    "            pass    \n",
    "\n",
    "\n",
    "    output = {}\n",
    "\n",
    "    for i, s in enumerate (gen_smiles):\n",
    "        ss = Chem.MolToSmiles(Chem.MolFromSmiles(s, sanitize=True), canonical=True)\n",
    "        gen_smiles[i] = ss\n",
    "\n",
    "    output['SMILES'] = gen_smiles\n",
    "    output['des_gap'] = sample_ys\n",
    "    # More accurate for regressor to predict gap from canonical SMILES\n",
    "    output['pred_gap'] = predss_can\n",
    "    #output['Err_pred_des'] = gen_error\n",
    "    output['Err_pred_des'] = [abs(i- j)/i for i, j in zip(output['des_gap'], output['pred_gap'])]\n",
    "    output = pd.DataFrame(output)\n",
    "    output.reset_index(drop = True, inplace = True)\n",
    "    output.to_csv ('./../experiments/regular/Initial_training.csv', index=False)\n",
    "\n",
    "    ## Statistics  (# pred=True value, Des=prediction)\n",
    "    # total # of samples\n",
    "    N = len(predss_can)\n",
    "    print ('random seed', rand)\n",
    "\n",
    "    # Explained Variance R2 from sklearn.metrics.explained_variance_score\n",
    "    explained_variance_R2_pred_des = explained_variance_score(output['des_gap'], output['pred_gap'])\n",
    "    print (\"explained_varice_R2_pred_des\", explained_variance_R2_pred_des)\n",
    "    rsquared = np.round (r2_score (output['des_gap'], output['pred_gap']), 4)\n",
    "    print (\"r squared r**2\", rsquared)\n",
    "\n",
    "    # mean absolute error \n",
    "    MAE_pred_des = np.round (mean_absolute_error(output['pred_gap'], output['des_gap']), 4)\n",
    "    print (\"MAE_pred_des\", MAE_pred_des)\n",
    "    # Fractioned MAE, more normalized\n",
    "    Fractioned_MAE_pred_des = 0\n",
    "    for pred, des in zip(output['pred_gap'], output['des_gap']):\n",
    "        Fractioned_MAE_pred_des = Fractioned_MAE_pred_des +  abs(des-pred)/des\n",
    "    Fractioned_MAE_pred_des = Fractioned_MAE_pred_des/N\n",
    "    #print (\"Fractioned MAE_pred_des\", Fractioned_MAE_pred_des)\n",
    "\n",
    "    # root mean squared error (RMSE), sqrt(sklearn ouputs MSE)\n",
    "    RMSE_pred_des = mean_squared_error(output['pred_gap'], output['des_gap'])**0.5\n",
    "    #print (\"RMSE_pred_des\", RMSE_pred_des)\n",
    "\n",
    "    Fractioned_RMSE_pred_des = 0\n",
    "    for pred, des in zip(output['pred_gap'], output['des_gap']):\n",
    "        Fractioned_RMSE_pred_des = Fractioned_RMSE_pred_des + ((des-pred)/des)**2\n",
    "    Fractioned_RMSE_pred_des = (Fractioned_RMSE_pred_des/N)**0.5\n",
    "    #print (\"Fractioned_RMSE_pred_des\", Fractioned_RMSE_pred_des)\n",
    "\n",
    "    # do not drop duplicate\n",
    "    output2 = output.drop_duplicates(['SMILES'])\n",
    "    output2.reset_index(drop = True, inplace = True)\n",
    "    output2.to_csv('./../experiments/regular/Initial_training_nodub.csv', index = False)\n",
    "    \"\"\"with open('gen_pickles.pickle', 'wb') as f:\n",
    "        pickle.dump(gen_unique_pickles, f)\n",
    "    \"\"\"\n",
    "    #print ('% < 20 RE NODUP', sum (output2['Err_pred_des'] < 0.2) / output2['Err_pred_des'].shape[0])\n",
    "    less20RE_per = np.round ((sum(output['Err_pred_des'] <= 0.2) / output['Err_pred_des'].shape[0]), 4)\n",
    "    print ('% < 20 RE', less20RE_per)\n",
    "    output_len = len(output)\n",
    "    explained_variance_R2_pred_des = explained_variance_score(output['des_gap'], output['pred_gap'])\n",
    "    #print (\"explained_varice_R2_pred_des\", explained_variance_R2_pred_des)\n",
    "    mean_RE = np.round (np.mean (output['Err_pred_des']), 4)\n",
    "    print ('RE mean', mean_RE)\n",
    "\n",
    "    randS.append(rand)\n",
    "    rsquaredS.append(rsquared)\n",
    "    MAE_S.append(MAE_pred_des)\n",
    "    less20RE_perS.append(less20RE_per)\n",
    "    mean_RE_S.append(mean_RE)\n",
    "    output_lenS.append(output_len)\n",
    "    print (output_lenS)\n",
    "\n",
    "    if rsquared>max:\n",
    "        good_rand = rand\n",
    "        max = rsquared\n",
    "        best_r2 = rsquared\n",
    "        print ('best r2', best_r2)\n",
    "        print ('best random seed', good_rand)\n",
    "    \n",
    "    tf.compat.v1.keras.backend.clear_session()\n",
    "\n",
    "params = {}\n",
    "params ['rand'] = randS\n",
    "params ['r2'] = rsquaredS\n",
    "params ['MAE'] = MAE_S\n",
    "params ['less20RE_per'] = less20RE_perS\n",
    "params ['Average_RE'] = mean_RE_S\n",
    "params ['total_valid'] = output_lenS\n",
    "params = pd.DataFrame(params)\n",
    "params.reset_index(drop = True, inplace = True)\n",
    "params.to_csv ('./gen_params.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d68316d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('./single_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "623fc4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "sns.distplot(output['pred_gap'], bins=15,)\n",
    "plt.plot([output['des_gap'][0], output['des_gap'][0]], [0, 0.35], \n",
    "         label='Targ. $E_{gap}$: 8.29 (eV)')\n",
    "plt.legend()\n",
    "plt.xlim(0, 12)\n",
    "np.mean (output['pred_gap'])\n",
    "[i.set_linewidth(2) for i in ax.spines.values()]\n",
    "\n",
    "\n",
    "ax.tick_params(axis='both', direction='out', length=5, width=3, colors='black', \n",
    "               grid_alpha=0, labelsize='18')\n",
    "\n",
    "\n",
    "plt.xlabel(r'Pred. $E_{gap}$ (eV)', fontsize=18, \n",
    "           fontname='Arial', fontweight=\"bold\", labelpad=5)\n",
    "plt.ylabel('Density', fontsize=18, \n",
    "           fontname='Arial', fontweight=\"bold\", labelpad=5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./single_target.jpeg', dpi=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
