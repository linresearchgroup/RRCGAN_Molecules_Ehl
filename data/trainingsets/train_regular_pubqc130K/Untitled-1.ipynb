{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 23:03:45.272913: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-13 23:03:45.343751: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-13 23:03:45.678150: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-11.2/lib64:\n",
      "2023-06-13 23:03:45.678197: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-11.2/lib64:\n",
      "2023-06-13 23:03:45.678200: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from matplotlib import rc, rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.lines as mlines\n",
    "from   matplotlib.lines import Line2D\n",
    "from   matplotlib.colors import ListedColormap\n",
    "import matplotlib.ticker as tk\n",
    "\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "import multiprocessing\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import (Input, Dropout, LSTM, Reshape, LeakyReLU,\n",
    "                          Concatenate, ReLU, Flatten, Dense, Embedding,\n",
    "                          BatchNormalization, Activation, SpatialDropout1D,\n",
    "                          Conv2D, MaxPooling2D, UpSampling2D, Lambda)\n",
    "from tensorflow.keras.models     import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses     import mse, binary_crossentropy\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.metrics import  mean_squared_error as mse_keras\n",
    "from tensorflow.keras.backend import argmax as argmax\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow import one_hot\n",
    "from tensorflow.keras.models import Sequential \n",
    "\n",
    "from tensorflow.keras.utils import  to_categorical\n",
    "from tensorflow import random as randomtf\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "from progressbar import ProgressBar\n",
    "import seaborn as sns\n",
    "\n",
    "from chainer_chemistry.dataset.preprocessors import GGNNPreprocessor, construct_atomic_number_array\n",
    "preprocessor = GGNNPreprocessor()\n",
    "from rdkit import rdBase\n",
    "rdBase.DisableLog('rdApp.error')\n",
    "from rdkit import Chem\n",
    "\n",
    "import ntpath\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "randomtf.set_seed(10)\n",
    "os.environ['PYTHONHASHSEED'] = '10'\n",
    "np.random.seed(420)\n",
    "random.seed(123450)\n",
    "from progressbar import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./image_train.pickle', 'rb') as f:\n",
    "    X_smiles_train0, SMILES_train0, y_train00 = pickle.load(f)\n",
    "    \n",
    "with open('./image_test.pickle', 'rb') as f:\n",
    "    X_smiles_val0, SMILES_val0, y_val00 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smiles_train1 = X_smiles_train0[0:20000]\n",
    "X_smiles_train2 = X_smiles_train0[20000:40000]\n",
    "X_smiles_train3 = X_smiles_train0[40000:60000]\n",
    "X_smiles_train4 = X_smiles_train0[60000:80000]\n",
    "X_smiles_train5 = X_smiles_train0[80000:100000]\n",
    "X_smiles_train6 = X_smiles_train0[100000:]\n",
    "\n",
    "SMILES_train1 = SMILES_train0[0:20000]\n",
    "SMILES_train2 = SMILES_train0[20000:40000]\n",
    "SMILES_train3 = SMILES_train0[40000:60000]\n",
    "SMILES_train4 = SMILES_train0[60000:80000]\n",
    "SMILES_train5 = SMILES_train0[80000:100000]\n",
    "SMILES_train6 = SMILES_train0[100000:]\n",
    "\n",
    "y_train1 = y_train00[0:20000]\n",
    "y_train2 = y_train00[20000:40000]\n",
    "y_train3 = y_train00[40000:60000]\n",
    "y_train4 = y_train00[60000:80000]\n",
    "y_train5 = y_train00[80000:100000]\n",
    "y_train6 = y_train00[100000:]\n",
    "\n",
    "X_smiles_val1 = X_smiles_val0[0:15000]\n",
    "X_smiles_val2 = X_smiles_val0[15000:]\n",
    "\n",
    "SMILES_val1 = SMILES_val0[0:15000]\n",
    "SMILES_val2 = SMILES_val0[15000:]\n",
    "\n",
    "y_val1 = y_val00[0:15000]\n",
    "y_val2 = y_val00[15000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6101,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMILES_train6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./image_train1.pickle', 'wb') as f:\n",
    "    pickle.dump((X_smiles_train1, SMILES_train1, y_train1), f)\n",
    "with open('./image_train2.pickle', 'wb') as f:\n",
    "    pickle.dump((X_smiles_train2, SMILES_train2, y_train2), f)\n",
    "with open('./image_train3.pickle', 'wb') as f:\n",
    "    pickle.dump((X_smiles_train3, SMILES_train3, y_train3), f)\n",
    "with open('./image_train4.pickle', 'wb') as f:\n",
    "    pickle.dump((X_smiles_train4, SMILES_train4, y_train4), f)\n",
    "with open('./image_train5.pickle', 'wb') as f:\n",
    "    pickle.dump((X_smiles_train5, SMILES_train5, y_train5), f)\n",
    "with open('./image_train6.pickle', 'wb') as f:\n",
    "    pickle.dump((X_smiles_train6, SMILES_train6, y_train6), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./image_val1.pickle', 'wb') as f:\n",
    "    pickle.dump((X_smiles_val1, SMILES_val1, y_val1), f)\n",
    "with open('./image_val2.pickle', 'wb') as f:\n",
    "    pickle.dump((X_smiles_val2, SMILES_val2, y_val2), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
